
# ğŸš€ Advanced Multimodal Context Manager

ä¸€ä¸ªå¼ºå¤§çš„Open WebUIæ’ä»¶ï¼Œæä¾›æ™ºèƒ½é•¿ä¸Šä¸‹æ–‡ç®¡ç†å’Œå¤šæ¨¡æ€å†…å®¹å¤„ç†åŠŸèƒ½ã€‚

## ğŸ“‹ ç›®å½• | Table of Contents

- [ä¸­æ–‡æ–‡æ¡£](#ä¸­æ–‡æ–‡æ¡£)
- [English Documentation](#english-documentation)

---

# ä¸­æ–‡æ–‡æ¡£

## ğŸŒŸ åŠŸèƒ½ç‰¹æ€§

### ğŸ–¼ï¸ å¤šæ¨¡æ€å¤„ç†
- **æ™ºèƒ½å›¾ç‰‡è¯†åˆ«**ï¼šè‡ªåŠ¨å°†å›¾ç‰‡è½¬æ¢ä¸ºè¯¦ç»†çš„æ–‡æœ¬æè¿°
- **å¤šç§å¤„ç†ç­–ç•¥**ï¼šæ”¯æŒå…¨æ¨¡å‹å¤„ç†ã€éå¤šæ¨¡æ€æ¨¡å‹å¤„ç†ã€è‡ªå®šä¹‰åˆ—è¡¨ç­‰
- **å›¾ç‰‡ä¿¡æ¯ä¿ç•™**ï¼šåœ¨æ‘˜è¦è¿‡ç¨‹ä¸­ç¡®ä¿å›¾ç‰‡æè¿°ä¿¡æ¯ä¸ä¸¢å¤±
- **ç¼“å­˜æœºåˆ¶**ï¼šç›¸åŒå›¾ç‰‡å¤ç”¨è¯†åˆ«ç»“æœï¼Œæé«˜æ•ˆç‡

### ğŸ’¾ æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†
- **Tokené™åˆ¶ç®¡ç†**ï¼šæ ¹æ®æ¨¡å‹è‡ªåŠ¨è°ƒæ•´Tokenä½¿ç”¨é‡
- **ä¿æŠ¤ç­–ç•¥**ï¼šæ™ºèƒ½ä¿æŠ¤å½“å‰æŸ¥è¯¢å’Œæœ€è¿‘å¯¹è¯è½®æ¬¡
- **é€’å½’æ‘˜è¦**ï¼šå¤šè½®æ‘˜è¦ç¡®ä¿é‡è¦ä¿¡æ¯ä¸ä¸¢å¤±
- **ç´§æ€¥æˆªæ–­**ï¼šåœ¨æç«¯æƒ…å†µä¸‹çš„ä¿æŠ¤æœºåˆ¶

### ğŸ” å‘é‡æ£€ç´¢ï¼ˆé¢„ç•™åŠŸèƒ½ï¼‰
- **å¤šæ¨¡æ€å‘é‡**ï¼šæ”¯æŒå›¾ç‰‡å’Œæ–‡æœ¬æ··åˆå‘é‡åŒ–
- **è¯­ä¹‰æ£€ç´¢**ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³å†…å®¹
- **æ™ºèƒ½é‡æ’åº**ï¼šä¼˜åŒ–æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§æ’åº
- **å¤šç§å‘é‡ç­–ç•¥**ï¼šæ”¯æŒä¸åŒçš„å‘é‡åŒ–ç­–ç•¥

### ğŸ›ï¸ çµæ´»é…ç½®
- **å¤„ç†ç­–ç•¥**ï¼šå¯è‡ªå®šä¹‰å“ªäº›æ¨¡å‹éœ€è¦ç‰¹æ®Šå¤„ç†
- **å‚æ•°è°ƒèŠ‚**ï¼šä¸°å¯Œçš„é…ç½®é€‰é¡¹æ»¡è¶³ä¸åŒéœ€æ±‚
- **è°ƒè¯•æ¨¡å¼**ï¼šå¤šçº§è°ƒè¯•ä¿¡æ¯å¸®åŠ©é—®é¢˜æ’æŸ¥
- **å®æ—¶çŠ¶æ€**ï¼šå‰ç«¯æ˜¾ç¤ºå¤„ç†è¿›åº¦å’ŒçŠ¶æ€

## ğŸš€ å®‰è£…ä½¿ç”¨

### å®‰è£…æ­¥éª¤
1. æ‰“å¼€Open WebUIç®¡ç†ç•Œé¢
2. è¿›å…¥"è®¾ç½®" â†’ "ç®¡é“"
3. ç‚¹å‡»"+"æ·»åŠ æ–°ç®¡é“
4. å°†æ’ä»¶ä»£ç ç²˜è´´åˆ°ç¼–è¾‘å™¨ä¸­
5. ç‚¹å‡»"ä¿å­˜"å®Œæˆå®‰è£…

### åŸºç¡€é…ç½®
å®‰è£…åéœ€è¦é…ç½®ä»¥ä¸‹å…³é”®å‚æ•°ï¼š

```yaml
# å¿…éœ€é…ç½®
vision_api_key: "ä½ çš„è§†è§‰APIå¯†é’¥"
vision_api_base: "https://your-vision-api.com"

# å¯é€‰é…ç½®
multimodal_processing_strategy: "smart_adaptive"
enable_processing: true
```

## ğŸ“– è¯¦ç»†åŠŸèƒ½è¯´æ˜

### 1. å¤šæ¨¡æ€å¤„ç†åŠŸèƒ½

#### ğŸ¯ å¤„ç†ç­–ç•¥
- **æ™ºèƒ½è‡ªé€‚åº”** (`smart_adaptive`): æ ¹æ®æ¨¡å‹ç±»å‹å’Œä¸Šä¸‹æ–‡è‡ªåŠ¨é€‰æ‹©æœ€ä½³å¤„ç†æ–¹å¼
- **å…¨æ¨¡å‹å¤„ç†** (`all_models`): å¯¹æ‰€æœ‰æ¨¡å‹éƒ½è¿›è¡Œå›¾ç‰‡å¤„ç†
- **éå¤šæ¨¡æ€æ¨¡å‹** (`non_multimodal_only`): åªå¯¹ä¸æ”¯æŒå¤šæ¨¡æ€çš„æ¨¡å‹å¤„ç†
- **è‡ªå®šä¹‰åˆ—è¡¨** (`custom_list`): æ ¹æ®æŒ‡å®šçš„æ¨¡å‹åˆ—è¡¨è¿›è¡Œå¤„ç†

#### ğŸ–¼ï¸ å›¾ç‰‡å¤„ç†æµç¨‹
1. **æ£€æµ‹å›¾ç‰‡**ï¼šè‡ªåŠ¨è¯†åˆ«æ¶ˆæ¯ä¸­çš„å›¾ç‰‡å†…å®¹
2. **è°ƒç”¨è§†è§‰API**ï¼šå°†å›¾ç‰‡å‘é€åˆ°é…ç½®çš„è§†è§‰æ¨¡å‹
3. **ç”Ÿæˆæè¿°**ï¼šè·å–è¯¦ç»†çš„å›¾ç‰‡æè¿°æ–‡æœ¬
4. **æ›¿æ¢å†…å®¹**ï¼šå°†å›¾ç‰‡æ›¿æ¢ä¸ºæè¿°æ–‡æœ¬ï¼ˆä¿ç•™åŸå›¾çš„æƒ…å†µé™¤å¤–ï¼‰
5. **ç¼“å­˜ç»“æœ**ï¼šä¿å­˜è¯†åˆ«ç»“æœä¾›åç»­ä½¿ç”¨

#### ğŸ“¸ å›¾ç‰‡ä¿ç•™ç­–ç•¥
- **ä¿ç•™åŸå›¾**ï¼šå¯¹äºåŸç”Ÿæ”¯æŒå¤šæ¨¡æ€çš„æ¨¡å‹ï¼Œå¯é€‰æ‹©ä¿ç•™åŸå§‹å›¾ç‰‡
- **æ›¿æ¢ä¸ºæ–‡æœ¬**ï¼šå¯¹äºä¸æ”¯æŒå¤šæ¨¡æ€çš„æ¨¡å‹ï¼Œå°†å›¾ç‰‡æ›¿æ¢ä¸ºæ–‡æœ¬æè¿°
- **æ··åˆæ¨¡å¼**ï¼šæ ¹æ®ä¸Šä¸‹æ–‡é•¿åº¦åŠ¨æ€é€‰æ‹©å¤„ç†æ–¹å¼

### 2. æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†

#### ğŸ” ä¿æŠ¤æœºåˆ¶
- **å½“å‰æŸ¥è¯¢ä¿æŠ¤**ï¼šå§‹ç»ˆä¿æŠ¤ç”¨æˆ·çš„æœ€æ–°æŸ¥è¯¢
- **å¯¹è¯è½®æ¬¡ä¿æŠ¤**ï¼šä¿æŠ¤æŒ‡å®šæ•°é‡çš„å®Œæ•´å¯¹è¯è½®æ¬¡
- **é‡è¦æ¶ˆæ¯ä¿æŠ¤**ï¼šç¡®ä¿å…³é”®ä¿¡æ¯ä¸è¢«æ‘˜è¦ä¸¢å¤±

#### ğŸ“Š Tokenç®¡ç†
- **åŠ¨æ€é™åˆ¶**ï¼šæ ¹æ®æ¨¡å‹ç±»å‹è‡ªåŠ¨è°ƒæ•´Tokené™åˆ¶
- **å®‰å…¨æ¯”ä¾‹**ï¼šé¢„ç•™å®‰å…¨marginé˜²æ­¢è¶…é™
- **æ™ºèƒ½åˆ†é…**ï¼šåœ¨ä¿æŠ¤å’Œæ‘˜è¦ä¹‹é—´æ™ºèƒ½åˆ†é…Token

#### ğŸ”„ é€’å½’æ‘˜è¦
- **å¤šè½®æ‘˜è¦**ï¼šå¿…è¦æ—¶è¿›è¡Œå¤šè½®æ‘˜è¦å¤„ç†
- **è´¨é‡æ£€æŸ¥**ï¼šç¡®ä¿æ‘˜è¦è´¨é‡ç¬¦åˆè¦æ±‚
- **ä¿¡æ¯ä¿ç•™**ï¼šæœ€å¤§åŒ–ä¿ç•™é‡è¦ä¿¡æ¯

### 3. å‘é‡æ£€ç´¢åŠŸèƒ½ï¼ˆé¢„ç•™ï¼‰

#### ğŸ¯ æ£€ç´¢ç­–ç•¥
- **å¤šæ¨¡æ€ä¼˜å…ˆ**ï¼šä¼˜å…ˆä½¿ç”¨å¤šæ¨¡æ€å‘é‡è¿›è¡Œæ£€ç´¢
- **æ–‡æœ¬ä¼˜å…ˆ**ï¼šä¼˜å…ˆä½¿ç”¨æ–‡æœ¬å‘é‡è¿›è¡Œæ£€ç´¢
- **æ··åˆæ¨¡å¼**ï¼šç»“åˆå¤šç§å‘é‡ç±»å‹è¿›è¡Œæ£€ç´¢

#### ğŸ” ç›¸ä¼¼åº¦åŒ¹é…
- **åŠ¨æ€é˜ˆå€¼**ï¼šæ ¹æ®å†…å®¹ç±»å‹è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼
- **è¯­ä¹‰ç†è§£**ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦è€Œéå­—é¢åŒ¹é…
- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šè€ƒè™‘ä¸Šä¸‹æ–‡ä¿¡æ¯æé«˜åŒ¹é…å‡†ç¡®æ€§

## âš™ï¸ é…ç½®å‚æ•°è¯¦è§£

### åŸºç¡€æ§åˆ¶
- `enable_processing`: å¯ç”¨/ç¦ç”¨æ‰€æœ‰å¤„ç†åŠŸèƒ½
- `excluded_models`: æ’é™¤çš„æ¨¡å‹åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼‰
- `debug_level`: è°ƒè¯•çº§åˆ«ï¼ˆ0-3ï¼‰

### å¤šæ¨¡æ€é…ç½®
- `multimodal_processing_strategy`: å¤šæ¨¡æ€å¤„ç†ç­–ç•¥
- `force_vision_processing_models`: å¼ºåˆ¶å¤„ç†å›¾ç‰‡çš„æ¨¡å‹åˆ—è¡¨
- `preserve_images_in_multimodal`: å¤šæ¨¡æ€æ¨¡å‹æ˜¯å¦ä¿ç•™åŸå›¾
- `always_process_images_before_summary`: æ‘˜è¦å‰æ˜¯å¦æ€»æ˜¯å¤„ç†å›¾ç‰‡

### Tokenç®¡ç†
- `default_token_limit`: é»˜è®¤Tokené™åˆ¶
- `token_safety_ratio`: Tokenå®‰å…¨æ¯”ä¾‹
- `max_preserve_ratio`: ä¿æŠ¤æ¶ˆæ¯æœ€å¤§Tokenæ¯”ä¾‹
- `max_single_message_tokens`: å•æ¡æ¶ˆæ¯æœ€å¤§Tokenæ•°

### è§†è§‰APIé…ç½®
- `vision_api_base`: è§†è§‰APIåŸºç¡€URL
- `vision_api_key`: è§†è§‰APIå¯†é’¥
- `vision_model`: è§†è§‰æ¨¡å‹åç§°
- `vision_prompt_template`: è§†è§‰è¯†åˆ«æç¤ºè¯æ¨¡æ¿

### æ‘˜è¦é…ç½®
- `summary_api_base`: æ‘˜è¦APIåŸºç¡€URL
- `summary_api_key`: æ‘˜è¦APIå¯†é’¥
- `summary_model`: æ‘˜è¦æ¨¡å‹åç§°
- `max_summary_length`: æ‘˜è¦æœ€å¤§é•¿åº¦

## ğŸ”§ å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆå›¾ç‰‡æ²¡æœ‰è¢«å¤„ç†ï¼Ÿ
A: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. ç¡®è®¤`enable_multimodal`å·²å¯ç”¨
2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
3. ç¡®è®¤è§†è§‰APIé…ç½®æ­£ç¡®
4. æŸ¥çœ‹è°ƒè¯•æ—¥å¿—äº†è§£è¯¦ç»†ä¿¡æ¯

### Q: å¦‚ä½•ä¼˜åŒ–å¤„ç†é€Ÿåº¦ï¼Ÿ
A: å¯ä»¥å°è¯•ï¼š
1. è°ƒæ•´`max_concurrent_requests`å¢åŠ å¹¶å‘æ•°
2. ä½¿ç”¨ç¼“å­˜æœºåˆ¶é¿å…é‡å¤å¤„ç†
3. ä¼˜åŒ–`chunk_size`å’Œ`overlap_size`å‚æ•°
4. é€‰æ‹©åˆé€‚çš„å¤„ç†ç­–ç•¥

### Q: æ‘˜è¦è´¨é‡ä¸å¥½æ€ä¹ˆåŠï¼Ÿ
A: å¯ä»¥ï¼š
1. è°ƒæ•´`max_summary_length`å‚æ•°
2. ä¼˜åŒ–æ‘˜è¦æç¤ºè¯
3. å¢åŠ `max_recursion_depth`å…è®¸æ›´å¤šé€’å½’
4. æ£€æŸ¥æ‘˜è¦æ¨¡å‹æ˜¯å¦åˆé€‚

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.4.4
- æ–°å¢å¤šæ¨¡æ€å¤„ç†ç­–ç•¥é…ç½®
- ä¿®å¤å›¾ç‰‡ä¿¡æ¯åœ¨æ‘˜è¦ä¸­ä¸¢å¤±çš„é—®é¢˜
- å¢å¼ºå¯¹åŸç”Ÿå¤šæ¨¡æ€æ¨¡å‹çš„æ”¯æŒ
- ä¼˜åŒ–Tokenç®¡ç†å’Œä¿æŠ¤æœºåˆ¶

### v1.4.3
- å®ç°é€’å½’æ‘˜è¦åŠŸèƒ½
- æ·»åŠ æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†
- ä¼˜åŒ–å¤šæ¨¡æ€å¤„ç†æµç¨‹
- å¢åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯

---

# English Documentation

## ğŸŒŸ Features

### ğŸ–¼ï¸ Multimodal Processing
- **Intelligent Image Recognition**: Automatically converts images to detailed text descriptions
- **Multiple Processing Strategies**: Supports all models, non-multimodal models, custom lists, etc.
- **Image Information Preservation**: Ensures image descriptions are not lost during summarization
- **Caching Mechanism**: Reuses recognition results for identical images to improve efficiency

### ğŸ’¾ Smart Context Management
- **Token Limit Management**: Automatically adjusts token usage based on model
- **Protection Strategy**: Intelligently protects current queries and recent conversation rounds
- **Recursive Summarization**: Multi-round summarization ensures important information is not lost
- **Emergency Truncation**: Protection mechanism in extreme situations

### ğŸ” Vector Retrieval (Reserved Feature)
- **Multimodal Vectors**: Supports mixed vectorization of images and text
- **Semantic Retrieval**: Retrieves relevant content based on semantic similarity
- **Smart Reranking**: Optimizes relevance ranking of retrieval results
- **Multiple Vector Strategies**: Supports different vectorization strategies

### ğŸ›ï¸ Flexible Configuration
- **Processing Strategies**: Customizable model-specific processing
- **Parameter Adjustment**: Rich configuration options for different needs
- **Debug Mode**: Multi-level debug information for troubleshooting
- **Real-time Status**: Frontend display of processing progress and status

## ğŸš€ Installation & Usage

### Installation Steps
1. Open Open WebUI admin interface
2. Go to "Settings" â†’ "Pipelines"
3. Click "+" to add new pipeline
4. Paste the plugin code into the editor
5. Click "Save" to complete installation

### Basic Configuration
After installation, configure these key parameters:

```yaml
# Required Configuration
vision_api_key: "your-vision-api-key"
vision_api_base: "https://your-vision-api.com"

# Optional Configuration
multimodal_processing_strategy: "smart_adaptive"
enable_processing: true
```

## ğŸ“– Detailed Feature Description

### 1. Multimodal Processing

#### ğŸ¯ Processing Strategies
- **Smart Adaptive** (`smart_adaptive`): Automatically selects optimal processing based on model type and context
- **All Models** (`all_models`): Processes images for all models
- **Non-multimodal Only** (`non_multimodal_only`): Only processes for models that don't support multimodal
- **Custom List** (`custom_list`): Processes based on specified model list

#### ğŸ–¼ï¸ Image Processing Flow
1. **Detect Images**: Automatically identifies image content in messages
2. **Call Vision API**: Sends images to configured vision model
3. **Generate Descriptions**: Obtains detailed image description text
4. **Replace Content**: Replaces images with description text (except when preserving originals)
5. **Cache Results**: Saves recognition results for future use

#### ğŸ“¸ Image Preservation Strategy
- **Preserve Originals**: For native multimodal models, option to keep original images
- **Replace with Text**: For non-multimodal models, replace images with text descriptions
- **Hybrid Mode**: Dynamically choose processing method based on context length

### 2. Smart Context Management

#### ğŸ” Protection Mechanism
- **Current Query Protection**: Always protects user's latest query
- **Conversation Round Protection**: Protects specified number of complete conversation rounds
- **Important Message Protection**: Ensures key information is not lost in summarization

#### ğŸ“Š Token Management
- **Dynamic Limits**: Automatically adjusts token limits based on model type
- **Safety Ratio**: Reserves safety margin to prevent overflow
- **Smart Allocation**: Intelligently allocates tokens between protection and summarization

#### ğŸ”„ Recursive Summarization
- **Multi-round Summarization**: Performs multiple rounds of summarization when necessary
- **Quality Check**: Ensures summarization quality meets requirements
- **Information Retention**: Maximizes retention of important information

### 3. Vector Retrieval (Reserved)

#### ğŸ¯ Retrieval Strategies
- **Multimodal First**: Prioritizes multimodal vectors for retrieval
- **Text First**: Prioritizes text vectors for retrieval
- **Mixed Mode**: Combines multiple vector types for retrieval

#### ğŸ” Similarity Matching
- **Dynamic Thresholds**: Adjusts similarity thresholds based on content type
- **Semantic Understanding**: Based on semantic similarity rather than literal matching
- **Context Awareness**: Considers context information to improve matching accuracy

## âš™ï¸ Configuration Parameters

### Basic Control
- `enable_processing`: Enable/disable all processing functions
- `excluded_models`: List of excluded models (comma-separated)
- `debug_level`: Debug level (0-3)

### Multimodal Configuration
- `multimodal_processing_strategy`: Multimodal processing strategy
- `force_vision_processing_models`: List of models to force image processing
- `preserve_images_in_multimodal`: Whether to preserve original images in multimodal models
- `always_process_images_before_summary`: Whether to always process images before summarization

### Token Management
- `default_token_limit`: Default token limit
- `token_safety_ratio`: Token safety ratio
- `max_preserve_ratio`: Maximum token ratio for protected messages
- `max_single_message_tokens`: Maximum tokens for single message

### Vision API Configuration
- `vision_api_base`: Vision API base URL
- `vision_api_key`: Vision API key
- `vision_model`: Vision model name
- `vision_prompt_template`: Vision recognition prompt template

### Summarization Configuration
- `summary_api_base`: Summary API base URL
- `summary_api_key`: Summary API key
- `summary_model`: Summary model name
- `max_summary_length`: Maximum summary length

## ğŸ”§ FAQ

### Q: Why aren't images being processed?
A: Check the following:
1. Confirm `enable_multimodal` is enabled
2. Check if model is in exclusion list
3. Verify vision API configuration is correct
4. Check debug logs for detailed information

### Q: How to optimize processing speed?
A: Try:
1. Adjust `max_concurrent_requests` to increase concurrency
2. Use caching mechanism to avoid duplicate processing
3. Optimize `chunk_size` and `overlap_size` parameters
4. Choose appropriate processing strategy

### Q: What if summarization quality is poor?
A: You can:
1. Adjust `max_summary_length` parameter
2. Optimize summarization prompt
3. Increase `max_recursion_depth` for more recursion
4. Check if summary model is suitable

## ğŸ“ Changelog

### v1.4.4
- Added multimodal processing strategy configuration
- Fixed image information loss in summarization
- Enhanced support for native multimodal models
- Optimized token management and protection mechanisms

### v1.4.3
- Implemented recursive summarization functionality
- Added smart context management
- Optimized multimodal processing flow
- Added detailed debug information

---

## ğŸ¤ Contributing

We welcome contributions! Please feel free to:
- Report bugs
- Suggest new features
- Submit pull requests
- Improve documentation

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

Thanks to the Open WebUI community and all contributors who made this project possible.
