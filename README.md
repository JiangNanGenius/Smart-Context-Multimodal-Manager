---

### ğŸš€ Advanced Multimodal Context Manager Plugin
**æ™ºèƒ½é•¿ä¸Šä¸‹æ–‡ä¸å¤šæ¨¡æ€å†…å®¹å¤„ç†å™¨**

---
#### ğŸŒ Overview | æ¦‚è¿°
This plugin intelligently handles long-context conversations and multimodal content (text + images) in OpenWebUI. It automatically:
- Compresses long conversations using semantic retrieval and recursive summarization
- Adds image understanding capabilities to non-multimodal models
- Preserves critical context while staying within token limits
- Maintains conversation integrity with smart prioritization

æœ¬æ’ä»¶æ™ºèƒ½å¤„ç†é•¿ä¸Šä¸‹æ–‡å¯¹è¯å’Œå¤šæ¨¡æ€å†…å®¹ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰ã€‚å®ƒèƒ½è‡ªåŠ¨ï¼š
- ä½¿ç”¨è¯­ä¹‰æ£€ç´¢å’Œé€’å½’æ‘˜è¦å‹ç¼©é•¿å¯¹è¯
- ä¸ºä¸æ”¯æŒå¤šæ¨¡æ€çš„æ¨¡å‹æ·»åŠ å›¾åƒç†è§£èƒ½åŠ›
- åœ¨Tokené™åˆ¶å†…ä¿ç•™å…³é”®ä¸Šä¸‹æ–‡
- é€šè¿‡æ™ºèƒ½ä¼˜å…ˆçº§ä¿æŒå¯¹è¯å®Œæ•´æ€§

---
#### ğŸ”§ Installation | å®‰è£…
1. Place the plugin file in your OpenWebUI `plugins` directory
2. Install required dependencies:
```bash
pip install httpx tiktoken openai
```

---
#### âš™ï¸ Configuration | é…ç½®
Set these environment variables or configure in the plugin UI:
```env
# Vectorization service
VECTOR_API_BASE=https://ark.cn-beijing.volces.com/api/v3
VECTOR_API_KEY=your_api_key_here

# Summarization service
SUMMARY_API_BASE=https://ark.cn-beijing.volces.com/api/v3
SUMMARY_API_KEY=your_api_key_here

# Reranking service
RERANK_API_BASE=https://api.bochaai.com
RERANK_API_KEY=your_api_key_here
```

---
#### ğŸ”„ Workflow | è¿è¡Œæµç¨‹
```mermaid
graph TD
    A[New Message] --> B{Token Check}
    B -- Under Limit --> Z[Send to Model]
    B -- Over Limit --> C{Multimodal Processing?}
    C -- Yes --> D[Convert Images to Text]
    C -- No --> E[Context Processing]
    D --> E
    E --> F[Chunk Messages]
    F --> G[Semantic Search]
    G --> H[Rerank Relevant Chunks]
    H --> I[Build Enhanced Context]
    I --> J{Still Over Limit?}
    J -- Yes --> K[Recursive Summarization]
    J -- No --> L[Construct Final Messages]
    K --> L
    L --> M[Send to Model]
```

Detailed Steps | è¯¦ç»†æ­¥éª¤:
1. **Token Check**  
   - Calculate total tokens in conversation  
   - Compare against model's token limit (with safety margin)  
   - è®¡ç®—å¯¹è¯æ€»Tokenæ•°
   - ä¸æ¨¡å‹Tokené™åˆ¶æ¯”è¾ƒï¼ˆå«å®‰å…¨è¾¹é™…ï¼‰

2. **Multimodal Processing (if enabled)**  
   - For non-multimodal models: Convert images to text descriptions  
   - Uses vision models to describe image content  
   - å¯¹äºéå¤šæ¨¡æ€æ¨¡å‹ï¼šå°†å›¾ç‰‡è½¬æ¢ä¸ºæ–‡å­—æè¿°
   - ä½¿ç”¨è§†è§‰æ¨¡å‹æè¿°å›¾ç‰‡å†…å®¹

3. **Context Processing**  
   - Split conversation into intelligent chunks  
   - Perform semantic search using vector embeddings  
   - Rerank chunks by relevance to current query  
   - å°†å¯¹è¯æ‹†åˆ†ä¸ºæ™ºèƒ½åˆ†å—
   - ä½¿ç”¨å‘é‡åµŒå…¥è¿›è¡Œè¯­ä¹‰æœç´¢
   - æŒ‰ä¸å½“å‰æŸ¥è¯¢ç›¸å…³æ€§é‡æ’åˆ†å—

4. **Context Construction**  
   - Combine system messages + relevant context chunks + recent messages  
   - Preserve last 2 user-assistant exchanges intact  
   - ç»„åˆç³»ç»Ÿæ¶ˆæ¯ + ç›¸å…³ä¸Šä¸‹æ–‡å— + æœ€æ–°æ¶ˆæ¯
   - å®Œæ•´ä¿ç•™æœ€å2ç»„ç”¨æˆ·-åŠ©æ‰‹å¯¹è¯

5. **Recursive Summarization (if needed)**  
   - Create hierarchical summaries when context still exceeds limits  
   - Preserves key information through multiple summarization passes  
   - å½“ä¸Šä¸‹æ–‡ä»è¶…é™æ—¶åˆ›å»ºåˆ†å±‚æ‘˜è¦
   - é€šè¿‡å¤šè½®æ‘˜è¦ä¿ç•™å…³é”®ä¿¡æ¯

6. **Final Delivery**  
   - Send optimized context to LLM  
   - Maintain conversation flow while reducing token usage by 30-70%  
   - å‘é€ä¼˜åŒ–åçš„ä¸Šä¸‹æ–‡ç»™å¤§æ¨¡å‹
   - ä¿æŒå¯¹è¯æµç•…åŒæ—¶å‡å°‘30-70%çš„Tokenä½¿ç”¨

---
#### âš™ï¸ Configuration Options | é…ç½®å‚æ•°
| Parameter | Default | Description |
|-----------|---------|-------------|
| `enable_processing` | âœ… True | Enable/disable all processing |
| `enable_multimodal` | âœ… True | Add image understanding to non-vision models |
| `debug_level` | 1 | Debug verbosity (0-3) |
| `token_safety_ratio` | 0.85 | Safety buffer below model limit |
| `preserve_last_messages` | 2 | User+assistant pairs to keep intact |
| `vector_similarity_threshold` | 0.5 | Minimum relevance score for context chunks |
| `max_recursion_depth` | 3 | Max summary levels for long contexts |

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|-----------|---------|-------------|
| `enable_processing` | âœ… å¼€å¯ | å¯ç”¨/ç¦ç”¨æ‰€æœ‰å¤„ç†åŠŸèƒ½ |
| `enable_multimodal` | âœ… å¼€å¯ | ä¸ºéè§†è§‰æ¨¡å‹æ·»åŠ å›¾åƒç†è§£èƒ½åŠ› |
| `debug_level` | 1 | è°ƒè¯•è¯¦ç»†ç¨‹åº¦ (0-3) |
| `token_safety_ratio` | 0.85 | ä½äºæ¨¡å‹é™åˆ¶çš„å®‰å…¨ç¼“å†² |
| `preserve_last_messages` | 2 | ä¿ç•™å®Œæ•´çš„ç”¨æˆ·+åŠ©æ‰‹å¯¹è¯å¯¹æ•° |
| `vector_similarity_threshold` | 0.5 | ä¸Šä¸‹æ–‡å—çš„æœ€ä½ç›¸å…³æ€§åˆ†æ•° |
| `max_recursion_depth` | 3 | é•¿ä¸Šä¸‹æ–‡çš„æœ€å¤§æ‘˜è¦å±‚çº§ |

---
#### ğŸŒŸ Features | åŠŸèƒ½äº®ç‚¹
- **Context-Aware Compression**  
  Preserves relevant historical context using semantic similarity
- **Multimodal Bridge**  
  Enables image understanding for text-only models
- **Intelligent Chunking**  
  Splits content at natural language boundaries
- **Progressive Summarization**  
  Maintains information integrity through recursive abstraction
- **Visual Feedback**  
  Shows real-time processing status in OpenWebUI interface

- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥å‹ç¼©**  
  ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦ä¿ç•™ç›¸å…³å†å²ä¸Šä¸‹æ–‡
- **å¤šæ¨¡æ€æ¡¥æ¥**  
  ä¸ºçº¯æ–‡æœ¬æ¨¡å‹æ·»åŠ å›¾åƒç†è§£èƒ½åŠ›
- **æ™ºèƒ½åˆ†å—**  
  åœ¨è‡ªç„¶è¯­è¨€è¾¹ç•Œæ‹†åˆ†å†…å®¹
- **æ¸è¿›å¼æ‘˜è¦**  
  é€šè¿‡é€’å½’æŠ½è±¡ä¿æŒä¿¡æ¯å®Œæ•´æ€§
- **å¯è§†åŒ–åé¦ˆ**  
  åœ¨OpenWebUIç•Œé¢æ˜¾ç¤ºå®æ—¶å¤„ç†çŠ¶æ€

---
#### âš ï¸ Requirements | è¦æ±‚
- OpenWebUI v0.5.17+
- Python dependencies: `httpx`, `tiktoken`, `openai`
- API keys for:
  - Vectorization service
  - Summarization service
  - Reranking service (optional)

---
#### ğŸ› Debugging | è°ƒè¯•
Set debug level in plugin configuration:
- `0`: No debugging
- `1`: Basic processing info
- `2`: Detailed chunk-level info
- `3`: Full API request/response logging

åœ¨æ’ä»¶é…ç½®ä¸­è®¾ç½®è°ƒè¯•çº§åˆ«ï¼š
- `0`: æ— è°ƒè¯•
- `1`: åŸºæœ¬å¤„ç†ä¿¡æ¯
- `2`: è¯¦ç»†åˆ†å—ä¿¡æ¯
- `3`: å®Œæ•´APIè¯·æ±‚/å“åº”æ—¥å¿—

---
#### ğŸ“œ License | è®¸å¯è¯
MIT License - Free for personal and commercial use

---

This README provides comprehensive documentation in both English and Chinese, covering installation, configuration, workflow, features, and usage details for the Advanced Multimodal Context Manager plugin. The workflow diagram visually explains the processing pipeline, while the bilingual format makes it accessible to international users.
