"""
title: ğŸš€ Advanced Multimodal Context Manager
author: JiangNanGenius
version: 1.0.1
license: MIT
required_open_webui_version: 0.5.17
description: æ™ºèƒ½é•¿ä¸Šä¸‹æ–‡å’Œå¤šæ¨¡æ€å†…å®¹å¤„ç†å™¨ï¼Œæ”¯æŒå‘é‡åŒ–æ£€ç´¢ã€è¯­ä¹‰é‡æ’åºã€é€’å½’æ€»ç»“ç­‰åŠŸèƒ½
"""
import json
import hashlib
import asyncio
import re
from typing import Optional, List, Dict, Callable, Any, Tuple, Union
from pydantic import BaseModel, Field
from enum import Enum

# å¯¼å…¥æ‰€éœ€åº“
try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False
    tiktoken = None

try:
    import httpx
    HTTPX_AVAILABLE = True
except ImportError:
    HTTPX_AVAILABLE = False
    httpx = None

try:
    from openai import AsyncOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    AsyncOpenAI = None

# æ¨¡å‹é…ç½®
MULTIMODAL_MODELS = {
    "gpt-4o", "gpt-4o-mini", "gpt-4-vision-preview",
    "doubao-1.5-vision-pro", "doubao-1.5-vision-lite",
    "claude-3", "gemini-pro-vision"
}

# Visioné¢„å¤„ç†æ¨¡å‹é…ç½®
VISION_MODELS = [
    "doubao-1.5-vision-pro-250328",
    "doubao-1.5-vision-lite-250328", 
    "doubao-1.5-vision-pro",
    "doubao-1.5-vision-lite"
]

# Tokené™åˆ¶é…ç½®
MODEL_TOKEN_LIMITS = {
    "gpt-4o": 128000,
    "gpt-4o-mini": 128000,
    "gpt-4": 8192,
    "gpt-3.5-turbo": 16385,
    "doubao-1.5-thinking-pro": 128000,
    "doubao-1.5-vision-pro": 128000,
    "claude-3": 200000,
    "gemini-pro": 128000,
}

# å‘é‡åŒ–ç­–ç•¥æšä¸¾
class VectorStrategy(str, Enum):
    AUTO = "auto"  # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹
    MULTIMODAL_FIRST = "multimodal_first"  # ä¼˜å…ˆä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹
    TEXT_FIRST = "text_first"  # ä¼˜å…ˆä½¿ç”¨æ–‡æœ¬æ¨¡å‹
    MIXED = "mixed"  # æ··åˆä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹
    FALLBACK = "fallback"  # ä¸»æ¨¡å‹å¤±è´¥æ—¶ä½¿ç”¨å¤‡ç”¨æ¨¡å‹
    VISION_TO_TEXT = "vision_to_text"  # å›¾ç‰‡è½¬æ–‡æœ¬åç”¨æ–‡æœ¬å‘é‡

class Filter:
    class Valves(BaseModel):
        # === ğŸ›ï¸ åŸºç¡€å¼€å…³é…ç½® ===
        enable_processing: bool = Field(
            default=True,
            description="ğŸ”„ å¯ç”¨é•¿ä¸Šä¸‹æ–‡å’Œå¤šæ¨¡æ€å¤„ç†"
        )
        
        enable_multimodal: bool = Field(
            default=True,
            description="ğŸ–¼ï¸ å¯ç”¨å¤šæ¨¡æ€åŠŸèƒ½ï¼ˆä¸ºä¸æ”¯æŒå›¾ç‰‡çš„æ¨¡å‹æ·»åŠ è§†è§‰èƒ½åŠ›ï¼‰"
        )
        
        enable_vision_preprocessing: bool = Field(
            default=True,
            description="ğŸ‘ï¸ å¯ç”¨å›¾ç‰‡é¢„å¤„ç†ï¼ˆå°†å›¾ç‰‡è½¬æ¢ä¸ºæ–‡æœ¬æè¿°ï¼‰"
        )
        
        force_truncate_first: bool = Field(
            default=True,
            description="âœ‚ï¸ å¼ºåˆ¶å…ˆæˆªæ–­ï¼Œå†åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å¤„ç†åçš„æ¶ˆæ¯"
        )

        # === ğŸ“Š è°ƒè¯•é…ç½® ===
        debug_level: int = Field(
            default=1,
            description="ğŸ› è°ƒè¯•çº§åˆ«ï¼š0=å…³é—­ï¼Œ1=åŸºç¡€ï¼Œ2=è¯¦ç»†ï¼Œ3=å®Œæ•´",
            json_schema_extra={"enum": [0, 1, 2, 3]}
        )
        
        show_frontend_progress: bool = Field(
            default=True,
            description="ğŸ“± æ˜¾ç¤ºå‰ç«¯å¤„ç†è¿›åº¦"
        )

        # === ğŸ¯ Tokenç®¡ç†é…ç½® ===
        default_token_limit: int = Field(
            default=120000,
            description="âš–ï¸ é»˜è®¤tokené™åˆ¶ï¼ˆå½“æ¨¡å‹æœªé…ç½®æ—¶ä½¿ç”¨ï¼‰"
        )
        
        token_safety_ratio: float = Field(
            default=0.85,
            description="ğŸ›¡ï¸ Tokenå®‰å…¨æ¯”ä¾‹ï¼ˆå®é™…é™åˆ¶=æ¨¡å‹é™åˆ¶*æ­¤æ¯”ä¾‹ï¼‰"
        )
        
        preserve_last_messages: int = Field(
            default=2,
            description="ğŸ’¾ å¼ºåˆ¶ä¿ç•™çš„æœ€åæ¶ˆæ¯æ•°é‡ï¼ˆuser+assistantå¯¹ï¼‰"
        )
        
        context_preserve_ratio: float = Field(
            default=0.6,
            description="ğŸ“ ä¸Šä¸‹æ–‡ä¿ç•™æ¯”ä¾‹ï¼ˆ0.6=ä¿ç•™60%åŸæ–‡ï¼Œ40%ç”¨äºæ‘˜è¦ï¼‰"
        )

        # === ğŸ‘ï¸ Visioné¢„å¤„ç†é…ç½® ===
        vision_api_base: str = Field(
            default="https://ark.cn-beijing.volces.com/api/v3",
            description="ğŸ‘ï¸ Visioné¢„å¤„ç†APIåŸºç¡€URL"
        )
        
        vision_api_key: str = Field(
            default="",
            description="ğŸ”‘ Visioné¢„å¤„ç†APIå¯†é’¥"
        )
        
        vision_model: str = Field(
            default="doubao-1.5-vision-pro-250328",
            description="ğŸ§  Visioné¢„å¤„ç†æ¨¡å‹åç§°",
            json_schema_extra={"enum": VISION_MODELS}
        )
        
        vision_custom_model: str = Field(
            default="",
            description="ğŸ›ï¸ è‡ªå®šä¹‰Visionæ¨¡å‹åç§°ï¼ˆç•™ç©ºä½¿ç”¨é¢„è®¾ï¼‰"
        )
        
        vision_prompt_template: str = Field(
            default="è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦å¯¹è±¡ã€åœºæ™¯ã€æ–‡å­—ã€é¢œè‰²ã€å¸ƒå±€ç­‰æ‰€æœ‰å¯è§ä¿¡æ¯ã€‚æè¿°è¦å‡†ç¡®ã€å…·ä½“ã€å®Œæ•´ï¼Œä¾¿äºåç»­çš„è¯­ä¹‰æ£€ç´¢ã€‚",
            description="ğŸ‘ï¸ Visionæ¨¡å‹æç¤ºè¯æ¨¡æ¿"
        )

        # === ğŸŒ å‘é‡åŒ–æœåŠ¡é…ç½® - å¤šæ¨¡æ€æ¨¡å‹ ===
        enable_multimodal_vector: bool = Field(
            default=True,
            description="ğŸ–¼ï¸ å¯ç”¨å¤šæ¨¡æ€å‘é‡æ¨¡å‹"
        )
        
        multimodal_vector_api_base: str = Field(
            default="https://ark.cn-beijing.volces.com/api/v3",
            description="ğŸ”— å¤šæ¨¡æ€å‘é‡åŒ–APIåŸºç¡€URL"
        )
        
        multimodal_vector_api_key: str = Field(
            default="",
            description="ğŸ”‘ å¤šæ¨¡æ€å‘é‡åŒ–APIå¯†é’¥"
        )
        
        multimodal_vector_model: str = Field(
            default="doubao-embedding-vision-250615",
            description="ğŸ§  å¤šæ¨¡æ€å‘é‡æ¨¡å‹åç§°"
        )
        
        multimodal_vector_custom_model: str = Field(
            default="",
            description="ğŸ›ï¸ è‡ªå®šä¹‰å¤šæ¨¡æ€å‘é‡æ¨¡å‹åç§°ï¼ˆç•™ç©ºä½¿ç”¨é¢„è®¾ï¼‰"
        )

        # === ğŸŒ å‘é‡åŒ–æœåŠ¡é…ç½® - æ–‡æœ¬æ¨¡å‹ ===
        enable_text_vector: bool = Field(
            default=True,
            description="ğŸ“ å¯ç”¨æ–‡æœ¬å‘é‡æ¨¡å‹"
        )
        
        text_vector_api_base: str = Field(
            default="https://ark.cn-beijing.volces.com/api/v3",
            description="ğŸ”— æ–‡æœ¬å‘é‡åŒ–APIåŸºç¡€URL"
        )
        
        text_vector_api_key: str = Field(
            default="",
            description="ğŸ”‘ æ–‡æœ¬å‘é‡åŒ–APIå¯†é’¥"
        )
        
        text_vector_model: str = Field(
            default="doubao-embedding-large-text-250515",
            description="ğŸ§  æ–‡æœ¬å‘é‡æ¨¡å‹åç§°",
            json_schema_extra={"enum": [
                "doubao-embedding-large-text-250515",
                "doubao-embedding-large-text-240915",
                "text-embedding-ada-002",
                "text-embedding-3-small",
                "text-embedding-3-large"
            ]}
        )
        
        text_vector_custom_model: str = Field(
            default="",
            description="ğŸ›ï¸ è‡ªå®šä¹‰æ–‡æœ¬å‘é‡æ¨¡å‹åç§°ï¼ˆç•™ç©ºä½¿ç”¨é¢„è®¾ï¼‰"
        )

        # === ğŸ¯ å‘é‡åŒ–ç­–ç•¥é…ç½® ===
        vector_strategy: VectorStrategy = Field(
            default=VectorStrategy.AUTO,
            description="ğŸ¯ å‘é‡åŒ–ç­–ç•¥é€‰æ‹©"
        )
        
        vector_similarity_threshold: float = Field(
            default=0.5,
            description="ğŸ¯ å‘é‡ç›¸ä¼¼åº¦é˜ˆå€¼"
        )
        
        multimodal_similarity_threshold: float = Field(
            default=0.45,
            description="ğŸ–¼ï¸ å¤šæ¨¡æ€å†…å®¹ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé€šå¸¸è®¾ç½®è¾ƒä½ï¼‰"
        )
        
        text_similarity_threshold: float = Field(
            default=0.55,
            description="ğŸ“ çº¯æ–‡æœ¬å†…å®¹ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé€šå¸¸è®¾ç½®è¾ƒé«˜ï¼‰"
        )

        # === ğŸ”„ é‡æ’åºé…ç½® ===
        enable_reranking: bool = Field(
            default=True,
            description="ğŸ”„ å¯ç”¨è¯­ä¹‰é‡æ’åº"
        )
        
        rerank_api_base: str = Field(
            default="https://api.bochaai.com",
            description="ğŸ”„ é‡æ’åºAPIåŸºç¡€URL"
        )
        
        rerank_api_key: str = Field(
            default="",
            description="ğŸ”‘ é‡æ’åºAPIå¯†é’¥"
        )
        
        rerank_model: str = Field(
            default="gte-rerank",
            description="ğŸ§  é‡æ’åºæ¨¡å‹åç§°",
            json_schema_extra={"enum": [
                "gte-rerank",
                "bocha-semantic-reranker-cn",
                "bocha-semantic-reranker-en"
            ]}
        )
        
        rerank_custom_model: str = Field(
            default="",
            description="ğŸ›ï¸ è‡ªå®šä¹‰é‡æ’åºæ¨¡å‹åç§°ï¼ˆç•™ç©ºä½¿ç”¨é¢„è®¾ï¼‰"
        )
        
        rerank_top_k: int = Field(
            default=10,
            description="ğŸ” é‡æ’åºè¿”å›çš„Top-Kæ•°é‡"
        )

        # === ğŸ“‘ æ‘˜è¦é…ç½® ===
        summary_api_base: str = Field(
            default="https://ark.cn-beijing.volces.com/api/v3",
            description="ğŸ“ æ‘˜è¦APIåŸºç¡€URL"
        )
        
        summary_api_key: str = Field(
            default="",
            description="ğŸ”‘ æ‘˜è¦APIå¯†é’¥"
        )
        
        summary_model: str = Field(
            default="doubao-1.5-thinking-pro-250415",
            description="ğŸ§  æ‘˜è¦æ¨¡å‹åç§°"
        )
        
        summary_custom_model: str = Field(
            default="",
            description="ğŸ›ï¸ è‡ªå®šä¹‰æ‘˜è¦æ¨¡å‹åç§°ï¼ˆç•™ç©ºä½¿ç”¨é¢„è®¾ï¼‰"
        )
        
        max_summary_length: int = Field(
            default=3000,
            description="ğŸ“ å•æ¬¡æ‘˜è¦æœ€å¤§é•¿åº¦"
        )
        
        max_recursion_depth: int = Field(
            default=3,
            description="ğŸ”„ æœ€å¤§é€’å½’æ‘˜è¦æ·±åº¦"
        )

        # === âš¡ æ€§èƒ½é…ç½® ===
        max_concurrent_requests: int = Field(
            default=3,
            description="âš¡ æœ€å¤§å¹¶å‘è¯·æ±‚æ•°"
        )
        
        request_timeout: int = Field(
            default=60,
            description="â±ï¸ APIè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
        )
        
        chunk_size: int = Field(
            default=1000,
            description="ğŸ“„ æ–‡æœ¬åˆ†ç‰‡å¤§å°ï¼ˆtokensï¼‰"
        )
        
        overlap_size: int = Field(
            default=100,
            description="ğŸ”— åˆ†ç‰‡é‡å å¤§å°ï¼ˆtokensï¼‰"
        )

        @classmethod
        def model_validate(cls, v):
            """éªŒè¯é…ç½®"""
            if isinstance(v, dict):
                # ç¡®ä¿è‡³å°‘å¯ç”¨ä¸€ä¸ªå‘é‡æ¨¡å‹
                if not v.get('enable_multimodal_vector', True) and not v.get('enable_text_vector', True):
                    v['enable_text_vector'] = True  # å¼ºåˆ¶å¯ç”¨æ–‡æœ¬å‘é‡æ¨¡å‹
                
                # å¦‚æœå¯ç”¨visioné¢„å¤„ç†ä½†æ²¡æœ‰é…ç½®ï¼Œè‡ªåŠ¨é…ç½®
                if v.get('enable_vision_preprocessing', True) and not v.get('vision_api_key'):
                    # å°è¯•ä½¿ç”¨å¤šæ¨¡æ€å‘é‡APIé…ç½®
                    if v.get('multimodal_vector_api_key'):
                        v['vision_api_key'] = v['multimodal_vector_api_key']
                        v['vision_api_base'] = v.get('multimodal_vector_api_base', v['vision_api_base'])
                    # æˆ–è€…ä½¿ç”¨æ–‡æœ¬å‘é‡APIé…ç½®
                    elif v.get('text_vector_api_key'):
                        v['vision_api_key'] = v['text_vector_api_key']
                        v['vision_api_base'] = v.get('text_vector_api_base', v['vision_api_base'])
            
            return super().model_validate(v)

    def __init__(self):
        self.valves = self.Valves()
        self.toggle = True
        self.icon = """data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGZpbGw9Im5vbmUiIHZpZXdCb3g9IjAgMCAyNCAyNCIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZT0iY3VycmVudENvbG9yIj4KICA8cGF0aCBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGQ9Ik0xMiAzdjE4bTktOWwtOS05LTkgOSIgLz4KPC9zdmc+"""
        
        # åˆå§‹åŒ–çŠ¶æ€
        self._multimodal_vector_client = None
        self._text_vector_client = None
        self._summary_client = None
        self._vision_client = None
        self._encoding = None
        self.processing_cache = {}
        self.vision_cache = {}  # ç¼“å­˜å›¾ç‰‡æè¿°ç»“æœ

    # === ğŸ› ï¸ å·¥å…·å‡½æ•° ===
    def debug_log(self, level: int, message: str, emoji: str = "ğŸ”§"):
        """åˆ†çº§è°ƒè¯•æ—¥å¿—"""
        if self.valves.debug_level >= level:
            prefix = ["", "ğŸ›[DEBUG]", "ğŸ”[DETAIL]", "ğŸ“‹[VERBOSE]"][min(level, 3)]
            print(f"{prefix} {emoji} {message}")

    def get_encoding(self):
        """è·å–tokenç¼–ç å™¨"""
        if not TIKTOKEN_AVAILABLE:
            return None
        if self._encoding is None:
            self._encoding = tiktoken.get_encoding("cl100k_base")
        return self._encoding

    def count_tokens(self, text: str) -> int:
        """ç²¾ç¡®è®¡ç®—tokenæ•°é‡"""
        if not text:
            return 0
        encoding = self.get_encoding()
        if encoding is None:
            return len(text) // 4
        try:
            return len(encoding.encode(text))
        except:
            return len(text) // 4

    def count_message_tokens(self, message: dict) -> int:
        """è®¡ç®—å•ä¸ªæ¶ˆæ¯çš„tokenæ•°"""
        content = message.get("content", "")
        role = message.get("role", "")
        total_tokens = 0
        
        if isinstance(content, list):
            for item in content:
                if item.get("type") == "text":
                    text = item.get("text", "")
                    total_tokens += self.count_tokens(text)
                elif item.get("type") == "image_url":
                    # å›¾ç‰‡æŒ‰å›ºå®štokenè®¡ç®—
                    total_tokens += 1000
        elif isinstance(content, str):
            total_tokens = self.count_tokens(content)
        
        total_tokens += self.count_tokens(role) + 4
        return total_tokens

    def count_messages_tokens(self, messages: List[dict]) -> int:
        """è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„æ€»tokenæ•°"""
        return sum(self.count_message_tokens(msg) for msg in messages)

    def get_model_token_limit(self, model_name: str) -> int:
        """è·å–æ¨¡å‹çš„tokené™åˆ¶"""
        # ä»é…ç½®ä¸­æŸ¥æ‰¾
        limit = MODEL_TOKEN_LIMITS.get(model_name.lower())
        if limit:
            return int(limit * self.valves.token_safety_ratio)
        
        # æ¨¡ç³ŠåŒ¹é…
        for model_key, model_limit in MODEL_TOKEN_LIMITS.items():
            if model_key in model_name.lower():
                return int(model_limit * self.valves.token_safety_ratio)
        
        # ä½¿ç”¨é»˜è®¤å€¼
        return int(self.valves.default_token_limit * self.valves.token_safety_ratio)

    def is_multimodal_model(self, model_name: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ¨¡æ€æ¨¡å‹"""
        return any(mm_model in model_name.lower() for mm_model in MULTIMODAL_MODELS)

    def has_images_in_messages(self, messages: List[dict]) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡"""
        for message in messages:
            content = message.get("content", "")
            if isinstance(content, list):
                for item in content:
                    if item.get("type") == "image_url":
                        return True
        return False

    def has_images_in_content(self, content) -> bool:
        """æ£€æŸ¥å•ä¸ªå†…å®¹ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡"""
        if isinstance(content, list):
            for item in content:
                if item.get("type") == "image_url":
                    return True
        return False

    def extract_images_from_content(self, content) -> List[str]:
        """ä»å†…å®¹ä¸­æå–å›¾ç‰‡URL"""
        images = []
        if isinstance(content, list):
            for item in content:
                if item.get("type") == "image_url":
                    image_url = item.get("image_url", {}).get("url", "")
                    if image_url:
                        images.append(image_url)
        return images

    def validate_vector_config(self) -> Tuple[bool, str]:
        """éªŒè¯å‘é‡åŒ–é…ç½®"""
        if not self.valves.enable_multimodal_vector and not self.valves.enable_text_vector:
            return False, "è‡³å°‘éœ€è¦å¯ç”¨ä¸€ä¸ªå‘é‡æ¨¡å‹"
        
        if self.valves.enable_multimodal_vector and not self.valves.multimodal_vector_api_key:
            return False, "å¤šæ¨¡æ€å‘é‡æ¨¡å‹å·²å¯ç”¨ä½†ç¼ºå°‘APIå¯†é’¥"
        
        if self.valves.enable_text_vector and not self.valves.text_vector_api_key:
            return False, "æ–‡æœ¬å‘é‡æ¨¡å‹å·²å¯ç”¨ä½†ç¼ºå°‘APIå¯†é’¥"
        
        return True, "é…ç½®éªŒè¯é€šè¿‡"

    async def send_status(self, __event_emitter__, message: str, done: bool = True, emoji: str = "ğŸ”„"):
        """å‘é€çŠ¶æ€æ¶ˆæ¯åˆ°å‰ç«¯"""
        if __event_emitter__ and self.valves.show_frontend_progress:
            try:
                await __event_emitter__({
                    "type": "status",
                    "data": {
                        "description": f"{emoji} {message}",
                        "done": done,
                    },
                })
            except Exception as e:
                self.debug_log(1, f"å‘é€çŠ¶æ€å¤±è´¥: {e}", "âŒ")

    # === ğŸ‘ï¸ Visioné¢„å¤„ç† ===
    def get_vision_client(self):
        """è·å–Visionå®¢æˆ·ç«¯"""
        if not OPENAI_AVAILABLE:
            return None
        
        if self._vision_client is None:
            api_key = self.valves.vision_api_key
            if not api_key:
                return None
            
            self._vision_client = AsyncOpenAI(
                base_url=self.valves.vision_api_base,
                api_key=api_key,
                timeout=self.valves.request_timeout
            )
        
        return self._vision_client

    async def describe_image_with_vision(self, image_url: str, __event_emitter__) -> str:
        """ä½¿ç”¨Visionæ¨¡å‹æè¿°å›¾ç‰‡"""
        # æ£€æŸ¥ç¼“å­˜
        image_hash = hashlib.md5(image_url.encode()).hexdigest()
        if image_hash in self.vision_cache:
            self.debug_log(2, "ä½¿ç”¨ç¼“å­˜çš„å›¾ç‰‡æè¿°", "ğŸ’¾")
            return self.vision_cache[image_hash]
        
        client = self.get_vision_client()
        if not client:
            return "æ— æ³•å¤„ç†å›¾ç‰‡ï¼šç¼ºå°‘Vision APIé…ç½®"
        
        vision_model = self.valves.vision_custom_model or self.valves.vision_model
        
        try:
            await self.send_status(__event_emitter__, f"æ­£åœ¨åˆ†æå›¾ç‰‡å†…å®¹...", False, "ğŸ‘ï¸")
            
            response = await client.chat.completions.create(
                model=vision_model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": self.valves.vision_prompt_template},
                            {"type": "image_url", "image_url": {"url": image_url}}
                        ]
                    }
                ],
                max_tokens=800,
                temperature=0.2
            )
            
            if response.choices:
                description = response.choices[0].message.content.strip()
                # ç¼“å­˜ç»“æœ
                self.vision_cache[image_hash] = description
                self.debug_log(2, f"å›¾ç‰‡æè¿°ç”ŸæˆæˆåŠŸ: {description[:100]}...", "âœ…")
                return description
            else:
                return "å›¾ç‰‡æè¿°ç”Ÿæˆå¤±è´¥"
        
        except Exception as e:
            self.debug_log(1, f"Visionæ¨¡å‹è°ƒç”¨å¤±è´¥: {e}", "âŒ")
            return f"å›¾ç‰‡å¤„ç†é”™è¯¯: {str(e)[:100]}"

    async def preprocess_content_for_text_vector(self, content, __event_emitter__) -> str:
        """ä¸ºæ–‡æœ¬å‘é‡æ¨¡å‹é¢„å¤„ç†å†…å®¹ï¼ˆå°†å›¾ç‰‡è½¬æ¢ä¸ºæ–‡æœ¬æè¿°ï¼‰"""
        if isinstance(content, str):
            return content
        
        if isinstance(content, list):
            processed_parts = []
            has_images = False
            
            for item in content:
                if item.get("type") == "text":
                    processed_parts.append(item.get("text", ""))
                elif item.get("type") == "image_url":
                    has_images = True
                    image_url = item.get("image_url", {}).get("url", "")
                    if image_url and self.valves.enable_vision_preprocessing:
                        description = await self.describe_image_with_vision(image_url, __event_emitter__)
                        processed_parts.append(f"[å›¾ç‰‡æè¿°] {description}")
                    else:
                        processed_parts.append("[å›¾ç‰‡] æ— æ³•å¤„ç†")
            
            if has_images:
                self.debug_log(2, "å°†å¤šæ¨¡æ€å†…å®¹è½¬æ¢ä¸ºçº¯æ–‡æœ¬", "ğŸ”„")
            
            return " ".join(processed_parts)
        
        return str(content)

    # === ğŸ–¼ï¸ å¤šæ¨¡æ€å¤„ç† ===
    async def process_multimodal_content(self, messages: List[dict], __event_emitter__) -> List[dict]:
        """å¤„ç†å¤šæ¨¡æ€å†…å®¹"""
        if not self.valves.enable_multimodal:
            return messages
        
        has_images = self.has_images_in_messages(messages)
        if not has_images:
            return messages
        
        await self.send_status(__event_emitter__, "æ£€æµ‹åˆ°å›¾ç‰‡å†…å®¹ï¼Œå‡†å¤‡å¤„ç†...", False, "ğŸ–¼ï¸")
        
        processed_messages = []
        for message in messages:
            content = message.get("content", "")
            
            if isinstance(content, list):
                # å¤„ç†å¤šæ¨¡æ€æ¶ˆæ¯
                text_parts = []
                image_descriptions = []
                
                for item in content:
                    if item.get("type") == "text":
                        text_parts.append(item.get("text", ""))
                    elif item.get("type") == "image_url":
                        # æè¿°å›¾ç‰‡
                        image_url = item.get("image_url", {}).get("url", "")
                        if image_url:
                            try:
                                description = await self.describe_image_with_vision(image_url, __event_emitter__)
                                image_descriptions.append(f"[å›¾ç‰‡æè¿°] {description}")
                            except Exception as e:
                                self.debug_log(1, f"å›¾ç‰‡æè¿°å¤±è´¥: {e}", "âŒ")
                                image_descriptions.append("[å›¾ç‰‡] å¤„ç†å¤±è´¥")
                
                # åˆå¹¶æ–‡æœ¬å’Œå›¾ç‰‡æè¿°
                combined_content = " ".join(text_parts + image_descriptions)
                processed_message = message.copy()
                processed_message["content"] = combined_content
                processed_messages.append(processed_message)
            else:
                processed_messages.append(message)
        
        await self.send_status(__event_emitter__, "å¤šæ¨¡æ€å†…å®¹å¤„ç†å®Œæˆ", True, "âœ…")
        return processed_messages

    # === ğŸ”— å‘é‡åŒ–å’Œæ£€ç´¢ ===
    def choose_vector_model(self, content_type: str = "text", has_images: bool = False) -> Tuple[str, str, str, str]:
        """æ ¹æ®ç­–ç•¥é€‰æ‹©å‘é‡æ¨¡å‹
        Returns:
            Tuple[api_base, api_key, model_name, model_type]
        """
        strategy = self.valves.vector_strategy
        
        # è·å–å®é™…ä½¿ç”¨çš„æ¨¡å‹åç§°
        multimodal_model = self.valves.multimodal_vector_custom_model or self.valves.multimodal_vector_model
        text_model = self.valves.text_vector_custom_model or self.valves.text_vector_model
        
        # å…³é”®ä¿®å¤ï¼šå¦‚æœæœ‰å›¾ç‰‡ä½†å¤šæ¨¡æ€å‘é‡æ¨¡å‹ä¸å¯ç”¨ï¼Œå¼ºåˆ¶ä½¿ç”¨ VISION_TO_TEXT ç­–ç•¥
        if has_images and not self.valves.enable_multimodal_vector and self.valves.enable_text_vector:
            strategy = VectorStrategy.VISION_TO_TEXT
            self.debug_log(2, "æ£€æµ‹åˆ°å›¾ç‰‡ä½†å¤šæ¨¡æ€å‘é‡æ¨¡å‹ä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°VISION_TO_TEXTç­–ç•¥", "ğŸ”„")
        
        if strategy == VectorStrategy.AUTO:
            # è‡ªåŠ¨é€‰æ‹©ï¼šæœ‰å›¾ç‰‡ä¸”å¤šæ¨¡æ€æ¨¡å‹å¯ç”¨æ—¶ä½¿ç”¨å¤šæ¨¡æ€ï¼Œå¦åˆ™ä½¿ç”¨æ–‡æœ¬æ¨¡å‹
            if has_images and self.valves.enable_multimodal_vector:
                return (
                    self.valves.multimodal_vector_api_base,
                    self.valves.multimodal_vector_api_key,
                    multimodal_model,
                    "multimodal"
                )
            elif self.valves.enable_text_vector:
                return (
                    self.valves.text_vector_api_base,
                    self.valves.text_vector_api_key,
                    text_model,
                    "text"
                )
            elif self.valves.enable_multimodal_vector:
                return (
                    self.valves.multimodal_vector_api_base,
                    self.valves.multimodal_vector_api_key,
                    multimodal_model,
                    "multimodal"
                )
        
        elif strategy == VectorStrategy.MULTIMODAL_FIRST:
            # ä¼˜å…ˆä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹
            if self.valves.enable_multimodal_vector:
                return (
                    self.valves.multimodal_vector_api_base,
                    self.valves.multimodal_vector_api_key,
                    multimodal_model,
                    "multimodal"
                )
            elif self.valves.enable_text_vector:
                return (
                    self.valves.text_vector_api_base,
                    self.valves.text_vector_api_key,
                    text_model,
                    "text"
                )
        
        elif strategy == VectorStrategy.TEXT_FIRST or strategy == VectorStrategy.VISION_TO_TEXT:
            # ä¼˜å…ˆä½¿ç”¨æ–‡æœ¬æ¨¡å‹ï¼ˆVISION_TO_TEXTä¼šåœ¨å‘é‡åŒ–æ—¶é¢„å¤„ç†å›¾ç‰‡ï¼‰
            if self.valves.enable_text_vector:
                return (
                    self.valves.text_vector_api_base,
                    self.valves.text_vector_api_key,
                    text_model,
                    "text"
                )
            elif self.valves.enable_multimodal_vector:
                return (
                    self.valves.multimodal_vector_api_base,
                    self.valves.multimodal_vector_api_key,
                    multimodal_model,
                    "multimodal"
                )
        
        # é»˜è®¤è¿”å›å¯ç”¨çš„ç¬¬ä¸€ä¸ªæ¨¡å‹
        if self.valves.enable_text_vector:
            return (
                self.valves.text_vector_api_base,
                self.valves.text_vector_api_key,
                text_model,
                "text"
            )
        elif self.valves.enable_multimodal_vector:
            return (
                self.valves.multimodal_vector_api_base,
                self.valves.multimodal_vector_api_key,
                multimodal_model,
                "multimodal"
            )
        
        raise ValueError("æ²¡æœ‰å¯ç”¨çš„å‘é‡æ¨¡å‹")

    async def vectorize_content(self, content, __event_emitter__, content_type: str = "text", has_images: bool = False) -> Optional[List[float]]:
        """å‘é‡åŒ–å†…å®¹ï¼ˆæ™ºèƒ½å¤„ç†å›¾ç‰‡ï¼‰"""
        if not HTTPX_AVAILABLE:
            return None
        
        try:
            api_base, api_key, model_name, model_type = self.choose_vector_model(content_type, has_images)
        except ValueError as e:
            self.debug_log(1, f"é€‰æ‹©å‘é‡æ¨¡å‹å¤±è´¥: {e}", "âŒ")
            return None
        
        if not api_key:
            self.debug_log(1, f"å‘é‡æ¨¡å‹ {model_type} ç¼ºå°‘APIå¯†é’¥", "âŒ")
            return None
        
        # é¢„å¤„ç†å†…å®¹
        text_content = content
        if model_type == "text" and (has_images or self.has_images_in_content(content)):
            # æ–‡æœ¬å‘é‡æ¨¡å‹éœ€è¦å°†å›¾ç‰‡è½¬æ¢ä¸ºæ–‡æœ¬æè¿°
            text_content = await self.preprocess_content_for_text_vector(content, __event_emitter__)
