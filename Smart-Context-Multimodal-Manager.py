"""
title: ğŸš€ Advanced Multimodal Context Manager
author: JiangNanGenius
version: 1.1.0
license: MIT
required_open_webui_version: 0.5.17
description: æ™ºèƒ½é•¿ä¸Šä¸‹æ–‡å’Œå¤šæ¨¡æ€å†…å®¹å¤„ç†å™¨ï¼Œæ”¯æŒå‘é‡åŒ–æ£€ç´¢ã€è¯­ä¹‰é‡æ’åºã€é€’å½’æ€»ç»“ç­‰åŠŸèƒ½
"""
import json
import hashlib
import asyncio
import re
from typing import Optional, List, Dict, Callable, Any, Tuple, Union
from pydantic import BaseModel, Field
from enum import Enum

# å¯¼å…¥æ‰€éœ€åº“
try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False
    tiktoken = None

try:
    import httpx
    HTTPX_AVAILABLE = True
except ImportError:
    HTTPX_AVAILABLE = False
    httpx = None

try:
    from openai import AsyncOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    AsyncOpenAI = None

# æ¨¡å‹é…ç½®
MULTIMODAL_MODELS = {
    "gpt-4o", "gpt-4o-mini", "gpt-4-vision-preview",
    "doubao-1.5-vision-pro", "doubao-1.5-vision-lite",
    "claude-3", "gemini-pro-vision"
}

# Tokené™åˆ¶é…ç½®
MODEL_TOKEN_LIMITS = {
    "gpt-4o": 128000,
    "gpt-4o-mini": 128000,
    "gpt-4": 8192,
    "gpt-3.5-turbo": 16385,
    "doubao-1.5-thinking-pro": 128000,
    "doubao-1.5-vision-pro": 128000,
    "claude-3": 200000,
    "gemini-pro": 128000,
}

# å‘é‡åŒ–ç­–ç•¥æšä¸¾
class VectorStrategy(str, Enum):
    AUTO = "auto"  # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹
    MULTIMODAL_FIRST = "multimodal_first"  # ä¼˜å…ˆä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹
    TEXT_FIRST = "text_first"  # ä¼˜å…ˆä½¿ç”¨æ–‡æœ¬æ¨¡å‹
    MIXED = "mixed"  # æ··åˆä½¿ç”¨ä¸¤ä¸ªæ¨¡å‹
    FALLBACK = "fallback"  # ä¸»æ¨¡å‹å¤±è´¥æ—¶ä½¿ç”¨å¤‡ç”¨æ¨¡å‹
    VISION_TO_TEXT = "vision_to_text"  # å›¾ç‰‡è½¬æ–‡æœ¬åç”¨æ–‡æœ¬å‘é‡

class Filter:
    class Valves(BaseModel):
        # === ğŸ›ï¸ åŸºç¡€å¼€å…³é…ç½® ===
        enable_processing: bool = Field(
            default=True,
            description="ğŸ”„ å¯ç”¨é•¿ä¸Šä¸‹æ–‡å’Œå¤šæ¨¡æ€å¤„ç† | ä¸»å¼€å…³ï¼Œå…³é—­åæ’ä»¶ä¸å·¥ä½œ"
        )
        
        enable_multimodal: bool = Field(
            default=True,
            description="ğŸ–¼ï¸ å¯ç”¨å¤šæ¨¡æ€åŠŸèƒ½ | ä¸ºä¸æ”¯æŒå›¾ç‰‡çš„æ¨¡å‹æ·»åŠ è§†è§‰èƒ½åŠ›ï¼Œæ— è®ºæ˜¯å¦è¶…é™éƒ½ä¼šå¤„ç†å›¾ç‰‡å†…å®¹"
        )
        
        enable_vision_preprocessing: bool = Field(
            default=True,
            description="ğŸ‘ï¸ å¯ç”¨å›¾ç‰‡é¢„å¤„ç† | å½“ä½¿ç”¨æ–‡æœ¬å‘é‡æ¨¡å‹æ—¶ï¼Œè‡ªåŠ¨å°†å›¾ç‰‡è½¬æ¢ä¸ºè¯¦ç»†çš„æ–‡æœ¬æè¿°è¿›è¡Œå‘é‡åŒ–"
        )
        
        force_multimodal_check: bool = Field(
            default=True,
            description="ğŸ” å¼ºåˆ¶å¤šæ¨¡æ€æ£€æŸ¥ | å³ä½¿æœªè¶…é™ä¹Ÿæ£€æŸ¥å¹¶å¤„ç†å¤šæ¨¡æ€å†…å®¹ï¼Œç¡®ä¿évisionæ¨¡å‹ä¹Ÿèƒ½ç†è§£å›¾ç‰‡"
        )
        
        enable_context_processing: bool = Field(
            default=True,
            description="ğŸ“š å¯ç”¨ä¸Šä¸‹æ–‡å¤„ç† | å½“tokenè¶…é™æ—¶å¯ç”¨æ£€ç´¢å¢å¼ºæˆ–æ‘˜è¦å‹ç¼©åŠŸèƒ½"
        )

        # === ğŸ“Š è°ƒè¯•é…ç½® ===
        debug_level: int = Field(
            default=1,
            description="ğŸ› è°ƒè¯•çº§åˆ« | 0=å®Œå…¨å…³é—­ 1=åŸºç¡€ä¿¡æ¯(æ¨è) 2=è¯¦ç»†è¿‡ç¨‹ 3=å®Œæ•´è°ƒè¯•ä¿¡æ¯"
        )
        
        show_frontend_progress: bool = Field(
            default=True,
            description="ğŸ“± æ˜¾ç¤ºå‰ç«¯å¤„ç†è¿›åº¦ | åœ¨OpenWebUIç•Œé¢æ˜¾ç¤ºå®æ—¶å¤„ç†çŠ¶æ€ï¼Œå»ºè®®å¼€å¯ä»¥ä¾¿äº†è§£å¤„ç†è¿›åº¦"
        )

        # === ğŸ¯ Tokenç®¡ç†é…ç½® ===
        default_token_limit: int = Field(
            default=120000,
            description="âš–ï¸ é»˜è®¤tokené™åˆ¶ | å½“æ¨¡å‹æœªåœ¨å†…ç½®åˆ—è¡¨ä¸­æ—¶ä½¿ç”¨æ­¤é™åˆ¶ï¼Œå»ºè®®è®¾ç½®ä¸ºç›®æ ‡æ¨¡å‹å®é™…é™åˆ¶çš„85%"
        )
        
        token_safety_ratio: float = Field(
            default=0.85,
            description="ğŸ›¡ï¸ Tokenå®‰å…¨æ¯”ä¾‹ | å®é™…ä½¿ç”¨é™åˆ¶=æ¨¡å‹ä¸Šé™Ã—æ­¤æ¯”ä¾‹ï¼Œé¢„ç•™15%ç©ºé—´ç»™æ¨¡å‹å“åº”ï¼ŒèŒƒå›´0.7-0.9"
        )
        
        preserve_last_messages: int = Field(
            default=2,
            description="ğŸ’¾ å¼ºåˆ¶ä¿ç•™çš„æœ€åæ¶ˆæ¯æ•°é‡ | ä¿æŠ¤æœ€æ–°çš„Nå¯¹ç”¨æˆ·-åŠ©æ‰‹å¯¹è¯ä¸è¢«æ‘˜è¦ï¼Œç¡®ä¿ä¸Šä¸‹æ–‡è¿è´¯æ€§"
        )
        
        context_preserve_ratio: float = Field(
            default=0.6,
            description="ğŸ“ ä¸Šä¸‹æ–‡ä¿ç•™æ¯”ä¾‹ | æ£€ç´¢æ¨¡å¼ä¸‹ï¼Œ60%tokenç”¨äºåŸå§‹ä¸Šä¸‹æ–‡ï¼Œ40%ç”¨äºæ£€ç´¢ç»“æœï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´"
        )

        # === ğŸ‘ï¸ Visioné¢„å¤„ç†é…ç½® ===
        vision_api_base: str = Field(
            default="https://ark.cn-beijing.volces.com/api/v3",
            description="ğŸ‘ï¸ Visioné¢„å¤„ç†APIåœ°å€ | å›¾ç‰‡æè¿°æœåŠ¡çš„APIç«¯ç‚¹ï¼Œè±†åŒ…é»˜è®¤åœ°å€ï¼Œä¹Ÿå¯ä½¿ç”¨OpenAIç­‰å…¼å®¹æœåŠ¡"
        )
        
        vision_api_key: str = Field(
            default="",
            description="ğŸ”‘ Visioné¢„å¤„ç†APIå¯†é’¥ | ç•™ç©ºæ—¶ä¼šè‡ªåŠ¨å°è¯•ä½¿ç”¨å…¶ä»–å·²é…ç½®çš„APIå¯†é’¥"
        )
        
        vision_model: str = Field(
            default="doubao-1.5-vision-pro-250328",
            description="ğŸ§  Visioné¢„å¤„ç†æ¨¡å‹ | æ¨èï¼šdoubao-1.5-vision-pro-250328(é«˜è´¨é‡) doubao-1.5-vision-lite-250328(å¿«é€Ÿ) gpt-4o(å›½é™…)"
        )
        
        vision_prompt_template: str = Field(
            default="è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»è¦å¯¹è±¡ã€åœºæ™¯ã€æ–‡å­—ã€é¢œè‰²ã€å¸ƒå±€ç­‰æ‰€æœ‰å¯è§ä¿¡æ¯ã€‚æè¿°è¦å‡†ç¡®ã€å…·ä½“ã€å®Œæ•´ï¼Œä¾¿äºåç»­çš„è¯­ä¹‰æ£€ç´¢ã€‚",
            description="ğŸ‘ï¸ Visionæ¨¡å‹æç¤ºè¯ | ç”¨äºæŒ‡å¯¼å›¾ç‰‡æè¿°çš„ç”Ÿæˆï¼Œå¯æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´æè¿°é‡ç‚¹"
        )

        # === ğŸŒ å‘é‡åŒ–æœåŠ¡é…ç½® - å¤šæ¨¡æ€æ¨¡å‹ ===
        enable_multimodal_vector: bool = Field(
            default=True,
            description="ğŸ–¼ï¸ å¯ç”¨å¤šæ¨¡æ€å‘é‡æ¨¡å‹ | å¯ç›´æ¥å¤„ç†å›¾ç‰‡+æ–‡æœ¬çš„å‘é‡æ¨¡å‹ï¼Œè´¨é‡æ›´é«˜ä½†é€Ÿåº¦è¾ƒæ…¢"
        )
        
        multimodal_vector_api_base: str = Field(
            default="https://ark.cn-beijing.volces.com/api/v3",
            description="ğŸ”— å¤šæ¨¡æ€å‘é‡APIåœ°å€ | è±†åŒ…é»˜è®¤åœ°å€ï¼Œä¹Ÿå¯ä½¿ç”¨å…¶ä»–æ”¯æŒå¤šæ¨¡æ€çš„å‘é‡æœåŠ¡"
        )
        
        multimodal_vector_api_key: str = Field(
            default="",
            description="ğŸ”‘ å¤šæ¨¡æ€å‘é‡APIå¯†é’¥ | è±†åŒ…embeddingæœåŠ¡å¯†é’¥ï¼Œé€šå¸¸ä¸ä¸»æœåŠ¡å¯†é’¥ç›¸åŒ"
        )
        
        multimodal_vector_model: str = Field(
            default="doubao-embedding-vision-250615",
            description="ğŸ§  å¤šæ¨¡æ€å‘é‡æ¨¡å‹åç§° | æ¨èï¼šdoubao-embedding-vision-250615(æœ€æ–°) text-embedding-3-large(OpenAI) ç­‰"
        )

        # === ğŸŒ å‘é‡åŒ–æœåŠ¡é…ç½® - æ–‡æœ¬æ¨¡å‹ ===
        enable_text_vector: bool = Field(
            default=True,
            description="ğŸ“ å¯ç”¨æ–‡æœ¬å‘é‡æ¨¡å‹ | å¤„ç†çº¯æ–‡æœ¬çš„å‘é‡æ¨¡å‹ï¼Œé€Ÿåº¦å¿«ï¼Œé€‚åˆå¤§é‡æ–‡æœ¬å¤„ç†"
        )
        
        text_vector_api_base: str = Field(
            default="https://ark.cn-beijing.volces.com/api/v3",
            description="ğŸ”— æ–‡æœ¬å‘é‡APIåœ°å€ | å»ºè®®ä¸å¤šæ¨¡æ€APIä½¿ç”¨åŒä¸€æœåŠ¡ä»¥ç®€åŒ–é…ç½®"
        )
        
        text_vector_api_key: str = Field(
            default="",
            description="ğŸ”‘ æ–‡æœ¬å‘é‡APIå¯†é’¥ | å¯ä¸å¤šæ¨¡æ€APIå…±ç”¨å¯†é’¥"
        )
        
        text_vector_model: str = Field(
            default="doubao-embedding-large-text-250515",
            description="ğŸ§  æ–‡æœ¬å‘é‡æ¨¡å‹åç§° | æ¨èï¼šdoubao-embedding-large-text-250515(å¤§æ¨¡å‹) text-embedding-3-large(OpenAI) bge-large-zh(æœ¬åœ°)"
        )

        # === ğŸ¯ å‘é‡åŒ–ç­–ç•¥é…ç½® ===
        vector_strategy: VectorStrategy = Field(
            default=VectorStrategy.AUTO,
            description="ğŸ¯ å‘é‡åŒ–ç­–ç•¥ | auto=æ™ºèƒ½é€‰æ‹© multimodal_first=ä¼˜å…ˆå¤šæ¨¡æ€ text_first=ä¼˜å…ˆæ–‡æœ¬ mixed=åŒæ¨¡å‹ fallback=å¤±è´¥é‡è¯•"
        )
        
        vector_similarity_threshold: float = Field(
            default=0.5,
            description="ğŸ¯ åŸºç¡€ç›¸ä¼¼åº¦é˜ˆå€¼ | 0-1ä¹‹é—´ï¼Œå€¼è¶Šé«˜ç­›é€‰è¶Šä¸¥æ ¼ï¼Œå»ºè®®0.4-0.6ï¼Œå¯æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´"
        )
        
        multimodal_similarity_threshold: float = Field(
            default=0.45,
            description="ğŸ–¼ï¸ å¤šæ¨¡æ€å†…å®¹ç›¸ä¼¼åº¦é˜ˆå€¼ | å›¾ç‰‡å†…å®¹æ£€ç´¢é˜ˆå€¼ï¼Œé€šå¸¸æ¯”æ–‡æœ¬ç•¥ä½ï¼Œå› ä¸ºè§†è§‰è¯­ä¹‰åŒ¹é…è¾ƒå®½æ³›"
        )
        
        text_similarity_threshold: float = Field(
            default=0.55,
            description="ğŸ“ çº¯æ–‡æœ¬ç›¸ä¼¼åº¦é˜ˆå€¼ | æ–‡æœ¬æ£€ç´¢é˜ˆå€¼ï¼Œå¯ä»¥è®¾ç½®è¾ƒé«˜ä»¥ä¿è¯ç›¸å…³æ€§ï¼Œå»ºè®®0.5-0.7"
        )

        # === ğŸ”„ é‡æ’åºé…ç½® ===
        enable_reranking: bool = Field(
            default=True,
            description="ğŸ”„ å¯ç”¨è¯­ä¹‰é‡æ’åº | ä½¿ç”¨ä¸“é—¨çš„é‡æ’åºæ¨¡å‹è¿›ä¸€æ­¥ä¼˜åŒ–æ£€ç´¢ç»“æœé¡ºåºï¼Œæ˜¾è‘—æé«˜ç›¸å…³æ€§"
        )
        
        rerank_api_base: str = Field(
            default="https://api.bochaai.com",
            description="ğŸ”„ é‡æ’åºAPIåœ°å€ | åšæŸ¥AIç­‰é‡æ’åºæœåŠ¡åœ°å€ï¼Œä¹Ÿå¯ä½¿ç”¨å…¶ä»–å…¼å®¹æœåŠ¡"
        )
        
        rerank_api_key: str = Field(
            default="",
            description="ğŸ”‘ é‡æ’åºAPIå¯†é’¥ | ä¸“é—¨çš„é‡æ’åºæœåŠ¡å¯†é’¥ï¼Œä¸å¡«åˆ™è·³è¿‡é‡æ’åºæ­¥éª¤"
        )
        
        rerank_model: str = Field(
            default="gte-rerank",
            description="ğŸ§  é‡æ’åºæ¨¡å‹åç§° | æ¨èï¼šgte-rerank(é€šç”¨) bocha-semantic-reranker-cn(ä¸­æ–‡) bge-reranker-large(å¼€æº)"
        )
        
        rerank_top_k: int = Field(
            default=10,
            description="ğŸ” é‡æ’åºè¿”å›æ•°é‡ | æœ€ç»ˆè¿”å›ç»™æ¨¡å‹çš„æ£€ç´¢ç»“æœæ•°é‡ï¼Œå»ºè®®5-15ä¸ªï¼Œå¤ªå¤šä¼šå½±å“æ•ˆæœ"
        )

        # === ğŸ“‘ æ‘˜è¦é…ç½® ===
        summary_api_base: str = Field(
            default="https://ark.cn-beijing.volces.com/api/v3",
            description="ğŸ“ æ‘˜è¦æœåŠ¡APIåœ°å€ | ç”¨äºç”Ÿæˆå¯¹è¯æ‘˜è¦çš„æœåŠ¡ç«¯ç‚¹"
        )
        
        summary_api_key: str = Field(
            default="",
            description="ğŸ”‘ æ‘˜è¦æœåŠ¡APIå¯†é’¥ | å¯ä¸å‘é‡æœåŠ¡å…±ç”¨å¯†é’¥"
        )
        
        summary_model: str = Field(
            default="doubao-1.5-thinking-pro-250415",
            description="ğŸ§  æ‘˜è¦æ¨¡å‹åç§° | æ¨èï¼šdoubao-1.5-thinking-pro(é«˜è´¨é‡æ‘˜è¦) gpt-4o(å›½é™…) claude-3-5-sonnet(é•¿æ–‡æœ¬)"
        )
        
        max_summary_length: int = Field(
            default=3000,
            description="ğŸ“ å•æ¬¡æ‘˜è¦æœ€å¤§é•¿åº¦ | æ¯è½®æ‘˜è¦ç”Ÿæˆçš„æœ€å¤§å­—ç¬¦æ•°ï¼Œå»ºè®®2000-5000ï¼Œå¤ªçŸ­ä¼šä¸¢å¤±ä¿¡æ¯"
        )
        
        max_recursion_depth: int = Field(
            default=3,
            description="ğŸ”„ æœ€å¤§é€’å½’æ‘˜è¦æ·±åº¦ | é˜²æ­¢æ— é™é€’å½’ï¼Œé€šå¸¸3å±‚å·²è¶³å¤Ÿå¤„ç†æé•¿å¯¹è¯"
        )

        # === âš¡ æ€§èƒ½é…ç½® ===
        max_concurrent_requests: int = Field(
            default=3,
            description="âš¡ æœ€å¤§å¹¶å‘è¯·æ±‚æ•° | APIå¹¶å‘é™åˆ¶ï¼Œè¿‡é«˜å¯èƒ½è§¦å‘é™æµï¼Œå»ºè®®2-5ä¸ª"
        )
        
        request_timeout: int = Field(
            default=60,
            description="â±ï¸ APIè¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) | å•ä¸ªAPIè°ƒç”¨çš„æœ€å¤§ç­‰å¾…æ—¶é—´ï¼Œå»ºè®®30-120ç§’"
        )
        
        chunk_size: int = Field(
            default=1000,
            description="ğŸ“„ æ–‡æœ¬åˆ†ç‰‡å¤§å°(tokens) | å†å²æ¶ˆæ¯åˆ†ç‰‡çš„tokenæ•°é‡ï¼Œå½±å“æ£€ç´¢ç²’åº¦ï¼Œå»ºè®®500-2000"
        )
        
        overlap_size: int = Field(
            default=100,
            description="ğŸ”— åˆ†ç‰‡é‡å å¤§å°(tokens) | ç›¸é‚»åˆ†ç‰‡çš„é‡å éƒ¨åˆ†ï¼Œä¿è¯ä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼Œå»ºè®®chunk_sizeçš„10-20%"
        )

        @classmethod
        def model_validate(cls, v):
            """éªŒè¯å’Œä¿®æ­£é…ç½®"""
            if isinstance(v, dict):
                # ç¡®ä¿è‡³å°‘å¯ç”¨ä¸€ä¸ªå‘é‡æ¨¡å‹
                if not v.get('enable_multimodal_vector', True) and not v.get('enable_text_vector', True):
                    v['enable_text_vector'] = True
                    print("âš ï¸ è­¦å‘Šï¼šè‡³å°‘éœ€è¦å¯ç”¨ä¸€ä¸ªå‘é‡æ¨¡å‹ï¼Œå·²è‡ªåŠ¨å¯ç”¨æ–‡æœ¬å‘é‡æ¨¡å‹")
                
                # è‡ªåŠ¨é…ç½®vision API
                if v.get('enable_vision_preprocessing', True) and not v.get('vision_api_key'):
                    if v.get('multimodal_vector_api_key'):
                        v['vision_api_key'] = v['multimodal_vector_api_key']
                        v['vision_api_base'] = v.get('multimodal_vector_api_base', v['vision_api_base'])
                        print("ğŸ’¡ æç¤ºï¼šå·²è‡ªåŠ¨ä½¿ç”¨å¤šæ¨¡æ€å‘é‡APIé…ç½®visionæœåŠ¡")
                    elif v.get('text_vector_api_key'):
                        v['vision_api_key'] = v['text_vector_api_key']
                        v['vision_api_base'] = v.get('text_vector_api_base', v['vision_api_base'])
                        print("ğŸ’¡ æç¤ºï¼šå·²è‡ªåŠ¨ä½¿ç”¨æ–‡æœ¬å‘é‡APIé…ç½®visionæœåŠ¡")
                
                # æ£€æŸ¥é‡å å¤§å°åˆç†æ€§
                chunk_size = v.get('chunk_size', 1000)
                overlap_size = v.get('overlap_size', 100)
                if overlap_size >= chunk_size * 0.5:
                    v['overlap_size'] = int(chunk_size * 0.2)
                    print(f"âš ï¸ è­¦å‘Šï¼šé‡å å¤§å°è¿‡å¤§ï¼Œå·²è°ƒæ•´ä¸º {v['overlap_size']}")
                
                # æ£€æŸ¥ç›¸ä¼¼åº¦é˜ˆå€¼åˆç†æ€§
                for threshold_key in ['vector_similarity_threshold', 'multimodal_similarity_threshold', 'text_similarity_threshold']:
                    threshold = v.get(threshold_key, 0.5)
                    if threshold < 0 or threshold > 1:
                        v[threshold_key] = max(0, min(1, threshold))
                        print(f"âš ï¸ è­¦å‘Šï¼š{threshold_key} å·²è°ƒæ•´åˆ°åˆç†èŒƒå›´ [0,1]")
                
                # æ£€æŸ¥tokenå®‰å…¨æ¯”ä¾‹
                safety_ratio = v.get('token_safety_ratio', 0.85)
                if safety_ratio < 0.5 or safety_ratio > 0.95:
                    v['token_safety_ratio'] = max(0.5, min(0.95, safety_ratio))
                    print(f"âš ï¸ è­¦å‘Šï¼štokenå®‰å…¨æ¯”ä¾‹å·²è°ƒæ•´ä¸º {v['token_safety_ratio']}")
            
            return super().model_validate(v)

    def __init__(self):
        self.valves = self.Valves()
        self.toggle = True
        self.icon = """data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGZpbGw9Im5vbmUiIHZpZXdCb3g9IjAgMCAyNCAyNCIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZT0iY3VycmVudENvbG9yIj4KICA8cGF0aCBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGQ9Ik0xMiAzdjE4bTktOWwtOS05LTkgOSIgLz4KPC9zdmc+"""
        
        # åˆå§‹åŒ–çŠ¶æ€å’Œç¼“å­˜
        self._multimodal_vector_client = None
        self._text_vector_client = None
        self._summary_client = None
        self._vision_client = None
        self._encoding = None
        self.processing_cache = {}  # å¤„ç†ç»“æœç¼“å­˜
        self.vision_cache = {}      # å›¾ç‰‡æè¿°ç¼“å­˜
        self.vector_cache = {}      # å‘é‡è®¡ç®—ç¼“å­˜

    # === ğŸ› ï¸ æ ¸å¿ƒå·¥å…·å‡½æ•° ===
    def debug_log(self, level: int, message: str, emoji: str = "ğŸ”§"):
        """åˆ†çº§è°ƒè¯•æ—¥å¿—è¾“å‡º"""
        if self.valves.debug_level >= level:
            prefix = ["", "ğŸ›[DEBUG]", "ğŸ”[DETAIL]", "ğŸ“‹[VERBOSE]"][min(level, 3)]
            print(f"{prefix} {emoji} {message}")

    def get_encoding(self):
        """è·å–tiktokenç¼–ç å™¨ï¼Œç”¨äºç²¾ç¡®è®¡ç®—tokenæ•°é‡"""
        if not TIKTOKEN_AVAILABLE:
            return None
        if self._encoding is None:
            try:
                self._encoding = tiktoken.get_encoding("cl100k_base")
            except Exception as e:
                self.debug_log(1, f"è·å–tiktokenç¼–ç å™¨å¤±è´¥: {e}", "âš ï¸")
        return self._encoding

    def count_tokens(self, text: str) -> int:
        """ç²¾ç¡®è®¡ç®—æ–‡æœ¬çš„tokenæ•°é‡"""
        if not text:
            return 0
        
        encoding = self.get_encoding()
        if encoding is None:
            return len(text) // 4
        
        try:
            return len(encoding.encode(text))
        except Exception as e:
            self.debug_log(2, f"Tokenè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ä¼°ç®—: {e}", "âš ï¸")
            return len(text) // 4

    def count_message_tokens(self, message: dict) -> int:
        """è®¡ç®—å•ä¸ªæ¶ˆæ¯çš„tokenæ•°ï¼ŒåŒ…æ‹¬è§’è‰²æ ‡è¯†å’Œæ ¼å¼å¼€é”€"""
        content = message.get("content", "")
        role = message.get("role", "")
        total_tokens = 0
        
        if isinstance(content, list):
            for item in content:
                if item.get("type") == "text":
                    text = item.get("text", "")
                    total_tokens += self.count_tokens(text)
                elif item.get("type") == "image_url":
                    total_tokens += 1000  # å›¾ç‰‡æŒ‰ç»éªŒå€¼è®¡ç®—
        elif isinstance(content, str):
            total_tokens = self.count_tokens(content)
        
        total_tokens += self.count_tokens(role) + 4
        return total_tokens

    def count_messages_tokens(self, messages: List[dict]) -> int:
        """è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„æ€»tokenæ•°"""
        return sum(self.count_message_tokens(msg) for msg in messages)

    def get_model_token_limit(self, model_name: str) -> int:
        """è·å–æ¨¡å‹çš„å®é™…å¯ç”¨tokené™åˆ¶"""
        limit = MODEL_TOKEN_LIMITS.get(model_name.lower())
        if limit:
            return int(limit * self.valves.token_safety_ratio)
        
        # æ¨¡ç³ŠåŒ¹é…
        for model_key, model_limit in MODEL_TOKEN_LIMITS.items():
            if model_key in model_name.lower():
                self.debug_log(2, f"æ¨¡å‹ {model_name} åŒ¹é…åˆ° {model_key}, é™åˆ¶: {model_limit}", "ğŸ¯")
                return int(model_limit * self.valves.token_safety_ratio)
        
        self.debug_log(1, f"æœªçŸ¥æ¨¡å‹ {model_name}, ä½¿ç”¨é»˜è®¤é™åˆ¶: {self.valves.default_token_limit}", "âš ï¸")
        return int(self.valves.default_token_limit * self.valves.token_safety_ratio)

    def is_multimodal_model(self, model_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŸç”Ÿæ”¯æŒå¤šæ¨¡æ€"""
        return any(mm_model in model_name.lower() for mm_model in MULTIMODAL_MODELS)

    def has_images_in_messages(self, messages: List[dict]) -> bool:
        """æ£€æŸ¥æ¶ˆæ¯åˆ—è¡¨ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡"""
        for message in messages:
            if self.has_images_in_content(message.get("content", "")):
                return True
        return False

    def has_images_in_content(self, content) -> bool:
        """æ£€æŸ¥å•ä¸ªå†…å®¹ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡"""
        if isinstance(content, list):
            for item in content:
                if item.get("type") == "image_url":
                    return True
        return False

    def extract_images_from_content(self, content) -> List[str]:
        """ä»å†…å®¹ä¸­æå–æ‰€æœ‰å›¾ç‰‡URL"""
        images = []
        if isinstance(content, list):
            for item in content:
                if item.get("type") == "image_url":
                    image_url = item.get("image_url", {}).get("url", "")
                    if image_url:
                        images.append(image_url)
        return images

    def should_process_multimodal(self, messages: List[dict], model_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œå¤šæ¨¡æ€å¤„ç†"""
        if not self.valves.enable_multimodal:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡å†…å®¹
        has_images = self.has_images_in_messages(messages)
        if not has_images:
            return False
        
        # æ£€æŸ¥ç›®æ ‡æ¨¡å‹æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€
        model_supports_multimodal = self.is_multimodal_model(model_name)
        
        # å¦‚æœæ¨¡å‹ä¸æ”¯æŒå¤šæ¨¡æ€ï¼Œæˆ–è€…å¼ºåˆ¶æ£€æŸ¥å¼€å¯ï¼Œåˆ™éœ€è¦å¤„ç†
        if not model_supports_multimodal or self.valves.force_multimodal_check:
            self.debug_log(2, f"éœ€è¦å¤šæ¨¡æ€å¤„ç†: æ¨¡å‹æ”¯æŒ={model_supports_multimodal}, å¼ºåˆ¶æ£€æŸ¥={self.valves.force_multimodal_check}", "ğŸ–¼ï¸")
            return True
        
        return False

    async def send_status(self, __event_emitter__, message: str, done: bool = True, emoji: str = "ğŸ”„"):
        """å‘å‰ç«¯å‘é€å¤„ç†çŠ¶æ€æ›´æ–°"""
        if __event_emitter__ and self.valves.show_frontend_progress:
            try:
                await __event_emitter__({
                    "type": "status",
                    "data": {
                        "description": f"{emoji} {message}",
                        "done": done,
                    },
                })
            except Exception as e:
                self.debug_log(1, f"çŠ¶æ€å‘é€å¤±è´¥: {e}", "âŒ")

    # === ğŸ‘ï¸ Visioné¢„å¤„ç†åŠŸèƒ½ ===
    def get_vision_client(self):
        """è·å–æˆ–åˆ›å»ºVision APIå®¢æˆ·ç«¯"""
        if not OPENAI_AVAILABLE:
            self.debug_log(1, "OpenAIåº“ä¸å¯ç”¨ï¼Œæ— æ³•ä½¿ç”¨VisionåŠŸèƒ½", "âŒ")
            return None
        
        if self._vision_client is None:
            api_key = self.valves.vision_api_key
            if not api_key:
                self.debug_log(1, "Vision APIå¯†é’¥æœªé…ç½®", "âš ï¸")
                return None
            
            self._vision_client = AsyncOpenAI(
                base_url=self.valves.vision_api_base,
                api_key=api_key,
                timeout=self.valves.request_timeout
            )
            self.debug_log(2, f"Visionå®¢æˆ·ç«¯å·²åˆ›å»º: {self.valves.vision_api_base}", "ğŸ‘ï¸")
        
        return self._vision_client

    async def describe_image_with_vision(self, image_url: str, __event_emitter__) -> str:
        """ä½¿ç”¨Visionæ¨¡å‹ç”Ÿæˆå›¾ç‰‡çš„è¯¦ç»†æ–‡æœ¬æè¿°"""
        image_hash = hashlib.md5(image_url.encode()).hexdigest()
        if image_hash in self.vision_cache:
            self.debug_log(2, f"ä½¿ç”¨ç¼“å­˜çš„å›¾ç‰‡æè¿°: {image_hash[:8]}...", "ğŸ’¾")
            return self.vision_cache[image_hash]
        
        client = self.get_vision_client()
        if not client:
            return "æ— æ³•å¤„ç†å›¾ç‰‡ï¼šVisionæœåŠ¡æœªé…ç½®"
        
        try:
            await self.send_status(__event_emitter__, f"æ­£åœ¨åˆ†æå›¾ç‰‡å†…å®¹...", False, "ğŸ‘ï¸")
            
            response = await client.chat.completions.create(
                model=self.valves.vision_model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": self.valves.vision_prompt_template},
                            {"type": "image_url", "image_url": {"url": image_url}}
                        ]
                    }
                ],
                max_tokens=800,
                temperature=0.2,
                timeout=self.valves.request_timeout
            )
            
            if response.choices and response.choices[0].message.content:
                description = response.choices[0].message.content.strip()
                self.vision_cache[image_hash] = description
                self.debug_log(2, f"å›¾ç‰‡æè¿°ç”ŸæˆæˆåŠŸ ({len(description)}å­—ç¬¦): {description[:50]}...", "âœ…")
                return description
            else:
                error_msg = "Visionæ¨¡å‹è¿”å›ç©ºå“åº”"
                self.debug_log(1, error_msg, "âŒ")
                return f"å›¾ç‰‡æè¿°å¤±è´¥: {error_msg}"
        
        except Exception as e:
            error_msg = f"Vision APIè°ƒç”¨å¤±è´¥: {str(e)[:100]}"
            self.debug_log(1, error_msg, "âŒ")
            return f"å›¾ç‰‡å¤„ç†é”™è¯¯: {error_msg}"

    async def process_multimodal_content(self, messages: List[dict], __event_emitter__) -> List[dict]:
        """å¤„ç†å¤šæ¨¡æ€å†…å®¹ï¼šä¸ºä¸æ”¯æŒå›¾ç‰‡çš„æ¨¡å‹æ·»åŠ è§†è§‰èƒ½åŠ›"""
        total_images = sum(len(self.extract_images_from_content(msg.get("content", ""))) 
                          for msg in messages)
        
        if total_images == 0:
            return messages
        
        await self.send_status(__event_emitter__, 
            f"æ£€æµ‹åˆ° {total_images} å¼ å›¾ç‰‡ï¼Œå¼€å§‹å¤šæ¨¡æ€å¤„ç†...", False, "ğŸ–¼ï¸")
        
        processed_messages = []
        processed_count = 0
        
        for i, message in enumerate(messages):
            content = message.get("content", "")
            
            if isinstance(content, list):
                text_parts = []
                image_descriptions = []
                
                for item in content:
                    if item.get("type") == "text":
                        text_content = item.get("text", "").strip()
                        if text_content:
                            text_parts.append(text_content)
                            
                    elif item.get("type") == "image_url":
                        processed_count += 1
                        image_url = item.get("image_url", {}).get("url", "")
                        
                        if image_url:
                            try:
                                await self.send_status(__event_emitter__, 
                                    f"å¤„ç†ç¬¬ {processed_count}/{total_images} å¼ å›¾ç‰‡...", False, "ğŸ‘ï¸")
                                
                                description = await self.describe_image_with_vision(image_url, __event_emitter__)
                                image_descriptions.append(f"[å›¾ç‰‡{processed_count}] {description}")
                                
                            except Exception as e:
                                self.debug_log(1, f"å›¾ç‰‡{processed_count}å¤„ç†å¤±è´¥: {e}", "âŒ")
                                image_descriptions.append(f"[å›¾ç‰‡{processed_count}] å¤„ç†å¤±è´¥: {str(e)[:50]}")
                
                all_content = text_parts + image_descriptions
                combined_content = " ".join(all_content) if all_content else ""
                
                processed_message = message.copy()
                processed_message["content"] = combined_content
                processed_messages.append(processed_message)
                
            else:
                processed_messages.append(message)
        
        await self.send_status(__event_emitter__, 
            f"å¤šæ¨¡æ€å¤„ç†å®Œæˆï¼š{processed_count} å¼ å›¾ç‰‡å·²è½¬æ¢ä¸ºæ–‡æœ¬", True, "âœ…")
        
        return processed_messages

    # === ğŸ”— å‘é‡åŒ–å’Œæ£€ç´¢åŠŸèƒ½ ===
    def choose_vector_model(self, content_type: str = "text", has_images: bool = False) -> Tuple[str, str, str, str]:
        """æ ¹æ®ç­–ç•¥å’Œå†…å®¹ç±»å‹æ™ºèƒ½é€‰æ‹©å‘é‡æ¨¡å‹"""
        strategy = self.valves.vector_strategy
        
        if has_images and not self.valves.enable_multimodal_vector and self.valves.enable_text_vector:
            strategy = VectorStrategy.VISION_TO_TEXT
            self.debug_log(2, "æ£€æµ‹åˆ°å›¾ç‰‡ä½†å¤šæ¨¡æ€å‘é‡ä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°VISION_TO_TEXTç­–ç•¥", "ğŸ”„")
        
        if strategy == VectorStrategy.AUTO:
            if has_images and self.valves.enable_multimodal_vector:
                return (
                    self.valves.multimodal_vector_api_base,
                    self.valves.multimodal_vector_api_key,
                    self.valves.multimodal_vector_model,
                    "multimodal"
                )
            elif self.valves.enable_text_vector:
                return (
                    self.valves.text_vector_api_base,
                    self.valves.text_vector_api_key,
                    self.valves.text_vector_model,
                    "text"
                )
            elif self.valves.enable_multimodal_vector:
                return (
                    self.valves.multimodal_vector_api_base,
                    self.valves.multimodal_vector_api_key,
                    self.valves.multimodal_vector_model,
                    "multimodal"
                )
        
        elif strategy == VectorStrategy.MULTIMODAL_FIRST:
            if self.valves.enable_multimodal_vector:
                return (
                    self.valves.multimodal_vector_api_base,
                    self.valves.multimodal_vector_api_key,
                    self.valves.multimodal_vector_model,
                    "multimodal"
                )
            elif self.valves.enable_text_vector:
                return (
                    self.valves.text_vector_api_base,
                    self.valves.text_vector_api_key,
                    self.valves.text_vector_model,
                    "text"
                )
        
        elif strategy in [VectorStrategy.TEXT_FIRST, VectorStrategy.VISION_TO_TEXT]:
            if self.valves.enable_text_vector:
                return (
                    self.valves.text_vector_api_base,
                    self.valves.text_vector_api_key,
                    self.valves.text_vector_model,
                    "text"
                )
            elif self.valves.enable_multimodal_vector:
                return (
                    self.valves.multimodal_vector_api_base,
                    self.valves.multimodal_vector_api_key,
                    self.valves.multimodal_vector_model,
                    "multimodal"
                )
        
        # é»˜è®¤é™çº§æ–¹æ¡ˆ
        if self.valves.enable_text_vector:
            return (
                self.valves.text_vector_api_base,
                self.valves.text_vector_api_key,
                self.valves.text_vector_model,
                "text"
            )
        elif self.valves.enable_multimodal_vector:
            return (
                self.valves.multimodal_vector_api_base,
                self.valves.multimodal_vector_api_key,
                self.valves.multimodal_vector_model,
                "multimodal"
            )
        
        raise ValueError("æ²¡æœ‰å¯ç”¨çš„å‘é‡æ¨¡å‹é…ç½®")

    async def preprocess_content_for_text_vector(self, content, __event_emitter__) -> str:
        """ä¸ºæ–‡æœ¬å‘é‡æ¨¡å‹é¢„å¤„ç†å†…å®¹ï¼šå°†å›¾ç‰‡è½¬æ¢ä¸ºæ–‡æœ¬æè¿°"""
        if isinstance(content, str):
            return content
        
        if isinstance(content, list):
            processed_parts = []
            image_count = 0
            
            for item in content:
                if item.get("type") == "text":
                    text_content = item.get("text", "").strip()
                    if text_content:
                        processed_parts.append(text_content)
                        
                elif item.get("type") == "image_url":
                    image_count += 1
                    image_url = item.get("image_url", {}).get("url", "")
                    
                    if image_url and self.valves.enable_vision_preprocessing:
                        description = await self.describe_image_with_vision(image_url, __event_emitter__)
                        processed_parts.append(f"[å›¾ç‰‡{image_count}æè¿°] {description}")
                    else:
                        processed_parts.append(f"[å›¾ç‰‡{image_count}] æ— æ³•å¤„ç†æˆ–åŠŸèƒ½å·²ç¦ç”¨")
            
            if image_count > 0:
                self.debug_log(2, f"å¤šæ¨¡æ€å†…å®¹å·²è½¬æ¢: {image_count}å¼ å›¾ç‰‡ -> æ–‡æœ¬æè¿°", "ğŸ”„")
            
            return " ".join(processed_parts)
        
        return str(content)

    async def vectorize_content(self, content, __event_emitter__, content_type: str = "text", has_images: bool = False) -> Optional[List[float]]:
        """æ™ºèƒ½å‘é‡åŒ–å†…å®¹ï¼Œè‡ªåŠ¨å¤„ç†å›¾ç‰‡è½¬æ–‡æœ¬"""
        if not HTTPX_AVAILABLE:
            self.debug_log(1, "httpxåº“ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œå‘é‡åŒ–", "âŒ")
            return None
        
        # ç”Ÿæˆç¼“å­˜key
        content_str = str(content)[:100]
        cache_key = hashlib.md5(f"{content_str}_{content_type}_{has_images}".encode()).hexdigest()
        
        if cache_key in self.vector_cache:
            self.debug_log(3, f"ä½¿ç”¨å‘é‡ç¼“å­˜: {cache_key[:8]}...", "ğŸ’¾")
            return self.vector_cache[cache_key]
        
        try:
            api_base, api_key, model_name, model_type = self.choose_vector_model(content_type, has_images)
        except ValueError as e:
            self.debug_log(1, f"å‘é‡æ¨¡å‹é€‰æ‹©å¤±è´¥: {e}", "âŒ")
            return None
        
        if not api_key:
            self.debug_log(1, f"å‘é‡æ¨¡å‹ {model_type} ç¼ºå°‘APIå¯†é’¥", "âŒ")
            return None
        
        # é¢„å¤„ç†å†…å®¹
        text_content = content
        preprocessing_info = ""
        
        if model_type == "text" and (has_images or self.has_images_in_content(content)):
            text_content = await self.preprocess_content_for_text_vector(content, __event_emitter__)
            preprocessing_info = " (å›¾ç‰‡â†’æ–‡æœ¬)"
            self.debug_log(2, f"å¤šæ¨¡æ€å†…å®¹å·²è½¬æ¢ä¸ºæ–‡æœ¬: {text_content[:100]}...", "ğŸ”„")
            
        elif isinstance(content, list):
            text_parts = []
            for item in content:
                if item.get("type") == "text":
                    text_parts.append(item.get("text", ""))
            text_content = " ".join(text_parts)
            
        elif not isinstance(content, str):
            text_content = str(content)
        
        url = f"{api_base}/embeddings"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        data = {
            "model": model_name,
            "input": text_content,
            "encoding_format": "float"
        }
        
        strategy_info = f"{self.valves.vector_strategy.value}{preprocessing_info}"
        self.debug_log(2, f"å‘é‡åŒ–: {model_type}æ¨¡å‹ {model_name} | ç­–ç•¥: {strategy_info}", "ğŸ§ ")
        
        try:
            async with httpx.AsyncClient(timeout=self.valves.request_timeout) as client:
                response = await client.post(url, headers=headers, json=data)
                response.raise_for_status()
                result = response.json()
                
                if "data" in result and result["data"] and result["data"][0].get("embedding"):
                    embedding = result["data"][0]["embedding"]
                    self.vector_cache[cache_key] = embedding
                    self.debug_log(3, f"å‘é‡åŒ–æˆåŠŸï¼Œç»´åº¦: {len(embedding)}", "âœ…")
                    return embedding
                else:
                    self.debug_log(1, "å‘é‡åŒ–å“åº”æ ¼å¼é”™è¯¯", "âŒ")
                    return None
        
        except Exception as e:
            self.debug_log(1, f"å‘é‡åŒ–å¤±è´¥ ({model_type}): {e}", "âŒ")
            if self.valves.vector_strategy == VectorStrategy.FALLBACK:
                return await self.try_fallback_vectorization(content, __event_emitter__, model_type, has_images)
            return None

    async def try_fallback_vectorization(self, content, __event_emitter__, failed_model_type: str, has_images: bool = False) -> Optional[List[float]]:
        """å°è¯•ä½¿ç”¨å¤‡ç”¨å‘é‡åŒ–æ¨¡å‹"""
        self.debug_log(2, f"å°è¯•å¤‡ç”¨å‘é‡åŒ–ï¼Œä¸»æ¨¡å‹({failed_model_type})å¤±è´¥", "ğŸ”„")
        
        try:
            if failed_model_type == "multimodal" and self.valves.enable_text_vector:
                api_base = self.valves.text_vector_api_base
                api_key = self.valves.text_vector_api_key
                model_name = self.valves.text_vector_model
                backup_type = "text"
                text_content = await self.preprocess_content_for_text_vector(content, __event_emitter__)
                
            elif failed_model_type == "text" and self.valves.enable_multimodal_vector:
                api_base = self.valves.multimodal_vector_api_base
                api_key = self.valves.multimodal_vector_api_key
                model_name = self.valves.multimodal_vector_model
                backup_type = "multimodal"
                
                if isinstance(content, list):
                    text_parts = []
                    for item in content:
                        if item.get("type") == "text":
                            text_parts.append(item.get("text", ""))
                    text_content = " ".join(text_parts)
                else:
                    text_content = str(content)
            else:
                self.debug_log(2, "æ²¡æœ‰å¯ç”¨çš„å¤‡ç”¨å‘é‡æ¨¡å‹", "âš ï¸")
                return None
            
            url = f"{api_base}/embeddings"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            data = {
                "model": model_name,
                "input": text_content,
                "encoding_format": "float"
            }
            
            async with httpx.AsyncClient(timeout=self.valves.request_timeout) as client:
                response = await client.post(url, headers=headers, json=data)
                response.raise_for_status()
                result = response.json()
                
                if "data" in result and result["data"] and result["data"][0].get("embedding"):
                    self.debug_log(2, f"å¤‡ç”¨å‘é‡æ¨¡å‹ {backup_type} æˆåŠŸ", "âœ…")
                    return result["data"][0]["embedding"]
                else:
                    return None
        
        except Exception as e:
            self.debug_log(1, f"å¤‡ç”¨å‘é‡åŒ–ä¹Ÿå¤±è´¥: {e}", "âŒ")
            return None

    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        try:
            import math
            
            dot_product = sum(a * b for a, b in zip(vec1, vec2))
            magnitude1 = math.sqrt(sum(a * a for a in vec1))
            magnitude2 = math.sqrt(sum(b * b for b in vec2))
            
            if magnitude1 == 0 or magnitude2 == 0:
                return 0.0
            
            similarity = dot_product / (magnitude1 * magnitude2)
            return max(-1.0, min(1.0, similarity))
            
        except Exception as e:
            self.debug_log(2, f"ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}", "âŒ")
            return 0.0

    def get_similarity_threshold(self, has_images: bool = False) -> float:
        """æ ¹æ®å†…å®¹ç±»å‹è·å–åˆé€‚çš„ç›¸ä¼¼åº¦é˜ˆå€¼"""
        if has_images:
            return self.valves.multimodal_similarity_threshold
        else:
            return self.valves.text_similarity_threshold

    # === ğŸ“š ä¸Šä¸‹æ–‡å¤„ç†åŠŸèƒ½ ===
    async def chunk_messages_intelligently(self, messages: List[dict]) -> List[Dict]:
        """æ™ºèƒ½åˆ†ç‰‡å†å²æ¶ˆæ¯ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§"""
        chunks = []
        current_chunk_content = ""
        current_chunk_tokens = 0
        current_chunk_messages = []
        
        self.debug_log(2, f"å¼€å§‹æ™ºèƒ½åˆ†ç‰‡ {len(messages)} æ¡æ¶ˆæ¯", "ğŸ“„")
        
        for i, message in enumerate(messages):
            content = message.get("content", "")
            has_images = self.has_images_in_content(content)
            
            if isinstance(content, list):
                text_parts = []
                for item in content:
                    if item.get("type") == "text":
                        text_parts.append(item.get("text", ""))
                    elif item.get("type") == "image_url":
                        text_parts.append("[å›¾ç‰‡å†…å®¹]")
                content_text = " ".join(text_parts)
            else:
                content_text = str(content)
            
            message_tokens = self.count_tokens(content_text)
            
            if (current_chunk_tokens + message_tokens > self.valves.chunk_size and 
                current_chunk_content):
                
                sentences = self.split_by_sentences(current_chunk_content)
                
                if len(sentences) > 1:
                    overlap_sentences = sentences[-max(1, len(sentences) // 5):]
                    overlap_content = " ".join(overlap_sentences)
                    overlap_tokens = self.count_tokens(overlap_content)
                    
                    chunks.append({
                        "content": current_chunk_content,
                        "messages": current_chunk_messages.copy(),
                        "index": len(chunks),
                        "tokens": current_chunk_tokens,
                        "has_images": any(self.has_images_in_content(msg.get("content")) 
                                        for msg in current_chunk_messages),
                        "sentence_count": len(sentences)
                    })
                    
                    if overlap_tokens <= self.valves.overlap_size:
                        current_chunk_content = overlap_content + " " + content_text
                        current_chunk_tokens = overlap_tokens + message_tokens
                    else:
                        current_chunk_content = content_text
                        current_chunk_tokens = message_tokens
                    
                    current_chunk_messages = [message]
                    
                else:
                    chunks.append({
                        "content": current_chunk_content,
                        "messages": current_chunk_messages.copy(),
                        "index": len(chunks),
                        "tokens": current_chunk_tokens,
                        "has_images": any(self.has_images_in_content(msg.get("content")) 
                                        for msg in current_chunk_messages),
                        "sentence_count": 1
                    })
                    
                    current_chunk_content = content_text
                    current_chunk_tokens = message_tokens
                    current_chunk_messages = [message]
            else:
                if current_chunk_content:
                    current_chunk_content += " " + content_text
                else:
                    current_chunk_content = content_text
                
                current_chunk_tokens += message_tokens
                current_chunk_messages.append(message)
        
        if current_chunk_content:
            chunks.append({
                "content": current_chunk_content,
                "messages": current_chunk_messages,
                "index": len(chunks),
                "tokens": current_chunk_tokens,
                "has_images": any(self.has_images_in_content(msg.get("content")) 
                                for msg in current_chunk_messages),
                "sentence_count": len(self.split_by_sentences(current_chunk_content))
            })
        
        self.debug_log(2, f"æ™ºèƒ½åˆ†ç‰‡å®Œæˆ: {len(chunks)}ä¸ªåˆ†ç‰‡, å¹³å‡{sum(c['tokens'] for c in chunks)//len(chunks) if chunks else 0}tokens/ç‰‡", "âœ…")
        
        return chunks

    def split_by_sentences(self, text: str) -> List[str]:
        """æŒ‰å¥å­è¾¹ç•Œåˆ†å‰²æ–‡æœ¬ï¼Œæ”¯æŒä¸­è‹±æ–‡"""
        if not text:
            return []
        
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿï¼›;]+\s*', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        return sentences

    async def semantic_search_and_rerank(self, query, chunks: List[Dict], __event_emitter__) -> List[Dict]:
        """è¯­ä¹‰æœç´¢å’Œé‡æ’åºï¼šä»å†å²åˆ†ç‰‡ä¸­æ‰¾åˆ°æœ€ç›¸å…³çš„å†…å®¹"""
        if not chunks:
            self.debug_log(1, "æ²¡æœ‰å¯æœç´¢çš„åˆ†ç‰‡", "âš ï¸")
            return []
        
        await self.send_status(__event_emitter__, 
            f"å¼€å§‹è¯­ä¹‰æ£€ç´¢ {len(chunks)} ä¸ªåˆ†ç‰‡...", False, "ğŸ”")
        
        # é¢„å¤„ç†æŸ¥è¯¢å†…å®¹
        query_text = query
        query_has_images = False
        
        if isinstance(query, list):
            text_parts = []
            for item in query:
                if item.get("type") == "text":
                    text_parts.append(item.get("text", ""))
                elif item.get("type") == "image_url":
                    query_has_images = True
            query_text = " ".join(text_parts)
        else:
            query_has_images = self.has_images_in_content(query)
        
        self.debug_log(2, f"æŸ¥è¯¢å†…å®¹: {query_text[:100]}... (åŒ…å«å›¾ç‰‡: {query_has_images})", "ğŸ”")
        
        # å‘é‡åŒ–æŸ¥è¯¢
        query_vector = await self.vectorize_content(query, __event_emitter__, "query", query_has_images)
        if not query_vector:
            self.debug_log(1, "æŸ¥è¯¢å‘é‡åŒ–å¤±è´¥ï¼Œè·³è¿‡è¯­ä¹‰æ£€ç´¢", "âš ï¸")
            return chunks[:self.valves.rerank_top_k]
        
        # è®¡ç®—ç›¸ä¼¼åº¦å¹¶ç­›é€‰
        scored_chunks = []
        processed_count = 0
        
        for chunk in chunks:
            processed_count += 1
            if processed_count % 5 == 0:
                await self.send_status(__event_emitter__, 
                    f"è®¡ç®—ç›¸ä¼¼åº¦... ({processed_count}/{len(chunks)})", False, "ğŸ§®")
            
            chunk_has_images = chunk.get("has_images", False)
            chunk_threshold = self.get_similarity_threshold(chunk_has_images)
            
            try:
                chunk_vector = await self.vectorize_content(
                    chunk["content"], __event_emitter__, "chunk", chunk_has_images
                )
                if chunk_vector:
                    similarity = self.cosine_similarity(query_vector, chunk_vector)
                    if similarity >= chunk_threshold:
                        chunk_copy = chunk.copy()
                        chunk_copy["similarity_score"] = similarity
                        scored_chunks.append(chunk_copy)
                        
                        self.debug_log(3, f"åˆ†ç‰‡{chunk['index']}: ç›¸ä¼¼åº¦{similarity:.3f} (é˜ˆå€¼{chunk_threshold:.3f})", "ğŸ“Š")
            except Exception as e:
                self.debug_log(3, f"åˆ†ç‰‡{chunk['index']}å‘é‡åŒ–å¤±è´¥: {e}", "âš ï¸")
                continue
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        scored_chunks.sort(key=lambda x: x["similarity_score"], reverse=True)
        
        await self.send_status(__event_emitter__, 
            f"è¯­ä¹‰æ£€ç´¢å®Œæˆï¼š{len(scored_chunks)}/{len(chunks)} ä¸ªåˆ†ç‰‡é€šè¿‡ç­›é€‰", True, "âœ…")
        
        # é‡æ’åºä¼˜åŒ–
        if (self.valves.enable_reranking and 
            self.valves.rerank_api_key and 
            len(scored_chunks) > 1):
            
            top_chunks = scored_chunks[:20]
            reranked_chunks = await self.rerank_chunks(query_text, top_chunks, __event_emitter__)
            return reranked_chunks[:self.valves.rerank_top_k]
        else:
            return scored_chunks[:self.valves.rerank_top_k]

    async def rerank_chunks(self, query: str, chunks: List[Dict], __event_emitter__) -> List[Dict]:
        """ä½¿ç”¨ä¸“é—¨çš„é‡æ’åºæœåŠ¡è¿›ä¸€æ­¥ä¼˜åŒ–æ£€ç´¢ç»“æœ"""
        if not HTTPX_AVAILABLE or not self.valves.rerank_api_key:
            self.debug_log(2, "é‡æ’åºæœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡æ­¤æ­¥éª¤", "âš ï¸")
            return chunks
        
        await self.send_status(__event_emitter__, 
            f"æ­£åœ¨é‡æ’åº {len(chunks)} ä¸ªç‰‡æ®µ...", False, "ğŸ”„")
        
        url = f"{self.valves.rerank_api_base}/v1/rerank"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.valves.rerank_api_key}"
        }
        
        documents = [chunk["content"] for chunk in chunks]
        
        data = {
            "model": self.valves.rerank_model,
            "query": query,
            "documents": documents,
            "top_n": min(self.valves.rerank_top_k, len(documents)),
            "return_documents": True
        }
        
        try:
            async with httpx.AsyncClient(timeout=self.valves.request_timeout) as client:
                response = await client.post(url, headers=headers, json=data)
                response.raise_for_status()
                result = response.json()
                
                if "data" in result and "results" in result["data"]:
                    reranked_chunks = []
                    for item in result["data"]["results"]:
                        original_index = item["index"]
                        chunk = chunks[original_index].copy()
                        chunk["rerank_score"] = item.get("relevance_score", item.get("score", 0))
                        reranked_chunks.append(chunk)
                    
                    await self.send_status(__event_emitter__, 
                        f"é‡æ’åºå®Œæˆï¼šä¼˜åŒ–äº† {len(reranked_chunks)} ä¸ªç»“æœ", True, "âœ…")
                    
                    self.debug_log(2, f"é‡æ’åºæˆåŠŸï¼Œè¿”å›{len(reranked_chunks)}ä¸ªç»“æœ", "ğŸ”„")
                    return reranked_chunks
                else:
                    self.debug_log(1, "é‡æ’åºå“åº”æ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨åŸå§‹æ’åº", "âš ï¸")
                    return chunks
        
        except Exception as e:
            self.debug_log(1, f"é‡æ’åºå¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ’åº", "âŒ")
            return chunks

    # === ğŸ“ æ‘˜è¦å¤„ç†åŠŸèƒ½ ===
    async def recursive_summarize(self, messages: List[dict], target_tokens: int, __event_emitter__, depth: int = 0) -> List[dict]:
        """é€’å½’æ‘˜è¦å¤„ç†ï¼šå½“å†…å®¹ä»ç„¶è¶…é™æ—¶è¿›è¡Œå¤šè½®æ‘˜è¦"""
        if depth >= self.valves.max_recursion_depth:
            self.debug_log(1, f"è¾¾åˆ°æœ€å¤§é€’å½’æ·±åº¦ {depth}ï¼Œå¼ºåˆ¶æˆªæ–­", "ğŸ”„")
            preserved = self.preserve_essential_messages(messages)
            return preserved
        
        current_tokens = self.count_messages_tokens(messages)
        if current_tokens <= target_tokens:
            self.debug_log(2, f"é€’å½’æ‘˜è¦depth={depth}: å·²æ»¡è¶³tokené™åˆ¶", "âœ…")
            return messages
        
        await self.send_status(__event_emitter__, 
            f"ç¬¬{depth+1}è½®é€’å½’æ‘˜è¦ ({current_tokens}â†’{target_tokens} tokens)", False, "ğŸ“")
        
        system_messages = [msg for msg in messages if msg.get("role") == "system"]
        other_messages = [msg for msg in messages if msg.get("role") != "system"]
        
        protected_count = self.valves.preserve_last_messages
        protected_messages = other_messages[-protected_count:] if len(other_messages) > protected_count else other_messages
        to_summarize = other_messages[:-protected_count] if len(other_messages) > protected_count else []
        
        if not to_summarize:
            await self.send_status(__event_emitter__, 
                "æ— æ³•ç»§ç»­æ‘˜è¦ï¼Œä¿ç•™æ ¸å¿ƒå†…å®¹", True, "âš ï¸")
            return system_messages + protected_messages
        
        self.debug_log(2, f"æ‘˜è¦ {len(to_summarize)} æ¡æ¶ˆæ¯ï¼Œä¿æŠ¤ {len(protected_messages)} æ¡", "ğŸ“")
        summary_text = await self.summarize_messages(to_summarize, __event_emitter__, depth)
        
        summary_message = {
            "role": "system",
            "content": f"=== ğŸ“‹ å†å²å¯¹è¯æ‘˜è¦ (ç¬¬{depth+1}è½®) ===\n{summary_text}\n{'='*50}"
        }
        
        new_messages = system_messages + [summary_message] + protected_messages
        new_tokens = self.count_messages_tokens(new_messages)
        
        if new_tokens > target_tokens:
            self.debug_log(2, f"é€’å½’æ‘˜è¦åä»è¶…é™ ({new_tokens}>{target_tokens})ï¼Œç»§ç»­ä¸‹ä¸€è½®", "ğŸ”„")
            return await self.recursive_summarize(new_messages, target_tokens, __event_emitter__, depth + 1)
        else:
            await self.send_status(__event_emitter__, 
                f"é€’å½’æ‘˜è¦å®Œæˆ ({current_tokens}â†’{new_tokens} tokens)", True, "âœ…")
            self.debug_log(1, f"é€’å½’æ‘˜è¦æˆåŠŸ: depth={depth}, {current_tokens}â†’{new_tokens} tokens", "ğŸ“")
            return new_messages

    def preserve_essential_messages(self, messages: List[dict]) -> List[dict]:
        """ä¿ç•™æœ€æ ¸å¿ƒçš„æ¶ˆæ¯ï¼šç³»ç»Ÿæ¶ˆæ¯+æœ€åä¸€å¯¹å¯¹è¯"""
        system_messages = [msg for msg in messages if msg.get("role") == "system"]
        other_messages = [msg for msg in messages if msg.get("role") != "system"]
        
        essential_others = other_messages[-1:] if other_messages else []
        
        return system_messages + essential_others

    async def summarize_messages(self, messages: List[dict], __event_emitter__, depth: int = 0) -> str:
        """ä½¿ç”¨AIæ¨¡å‹ç”Ÿæˆå¯¹è¯æ‘˜è¦"""
        if not OPENAI_AVAILABLE:
            return "æ— æ³•ç”Ÿæˆæ‘˜è¦ï¼šOpenAIåº“ä¸å¯ç”¨"
        
        api_key = self.valves.summary_api_key
        if not api_key:
            return "æ— æ³•ç”Ÿæˆæ‘˜è¦ï¼šAPIå¯†é’¥æœªé…ç½®"
        
        conversation_text = ""
        for i, msg in enumerate(messages):
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            
            if isinstance(content, list):
                text_parts = []
                image_count = 0
                for item in content:
                    if item.get("type") == "text":
                        text_parts.append(item.get("text", ""))
                    elif item.get("type") == "image_url":
                        image_count += 1
                        text_parts.append(f"[åŒ…å«å›¾ç‰‡{image_count}]")
                content = " ".join(text_parts)
            
            conversation_text += f"\n[{i+1}] {role}: {content}\n"
        
        client = AsyncOpenAI(
            base_url=self.valves.summary_api_base,
            api_key=api_key,
            timeout=self.valves.request_timeout
        )
        
        system_prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„å¯¹è¯æ‘˜è¦ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹å¯¹è¯åˆ›å»ºç®€æ´è€Œå®Œæ•´çš„æ‘˜è¦ã€‚

æ‘˜è¦è¦æ±‚ï¼š
1. **ä¿ç•™å…³é”®ä¿¡æ¯**ï¼šé‡è¦å†³å®šã€æŠ€æœ¯ç»†èŠ‚ã€æ•°æ®ã€ä»£ç ç‰‡æ®µã€é“¾æ¥ç­‰
2. **ä¿æŒé€»è¾‘é¡ºåº**ï¼šæŒ‰æ—¶é—´é¡ºåºç»„ç»‡ï¼Œæ ‡æ˜é‡è¦è½¬æŠ˜ç‚¹
3. **çªå‡ºæ ¸å¿ƒä¸»é¢˜**ï¼šè¯†åˆ«ä¸»è¦è®¨è®ºè¯é¢˜å’Œå­è¯é¢˜
4. **ä¿ç•™ä¸Šä¸‹æ–‡**ï¼šç»´æŒå¯¹è¯çš„å› æœå…³ç³»å’ŒèƒŒæ™¯ä¿¡æ¯
5. **æ§åˆ¶é•¿åº¦**ï¼šæ‘˜è¦é•¿åº¦ä¸è¶…è¿‡{self.valves.max_summary_length}å­—ç¬¦
6. **ç»“æ„åŒ–è¡¨è¾¾**ï¼šä½¿ç”¨æ ‡é¢˜ã€è¦ç‚¹ç­‰æ–¹å¼ç»„ç»‡å†…å®¹

å½“å‰é€’å½’æ·±åº¦ï¼š{depth}
åŸå§‹å¯¹è¯æ¡æ•°ï¼š{len(messages)}

å¯¹è¯å†…å®¹ï¼š"""
        
        try:
            await self.send_status(__event_emitter__, 
                f"ç”Ÿæˆå¯¹è¯æ‘˜è¦... ({len(conversation_text)}å­—ç¬¦)", False, "ğŸ¤–")
            
            response = await client.chat.completions.create(
                model=self.valves.summary_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": conversation_text}
                ],
                max_tokens=self.valves.max_summary_length,
                temperature=0.2,
                stream=False
            )
            
            if response.choices and response.choices[0].message.content:
                summary = response.choices[0].message.content.strip()
                self.debug_log(2, f"æ‘˜è¦ç”ŸæˆæˆåŠŸ ({len(summary)}å­—ç¬¦): {summary[:100]}...", "ğŸ“")
                return summary
            else:
                return "æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼šæ¨¡å‹è¿”å›ç©ºå“åº”"
        
        except Exception as e:
            error_msg = f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)[:200]}"
            self.debug_log(1, error_msg, "âŒ")
            
            fallback_summary = f"""å¯¹è¯æ‘˜è¦ï¼ˆé™çº§ç‰ˆæœ¬ï¼‰ï¼š
- æ€»æ¶ˆæ¯æ•°ï¼š{len(messages)}
- æ—¶é—´è·¨åº¦ï¼šä»ç¬¬1æ¡åˆ°ç¬¬{len(messages)}æ¡æ¶ˆæ¯
- ä¸»è¦å‚ä¸è€…ï¼š{', '.join(set(msg.get('role', 'unknown') for msg in messages))}
- é”™è¯¯ä¿¡æ¯ï¼š{str(e)[:100]}
æ³¨ï¼šç”±äºAPIè°ƒç”¨å¤±è´¥ï¼Œæ­¤ä¸ºè‡ªåŠ¨ç”Ÿæˆçš„ç®€åŒ–æ‘˜è¦ã€‚"""
            
            return fallback_summary

    # === ğŸ¯ æ ¸å¿ƒå¤„ç†é€»è¾‘ ===
    async def process_context_with_retrieval(self, messages: List[dict], model_name: str, __event_emitter__) -> List[dict]:
        """ä½¿ç”¨æ£€ç´¢å¢å¼ºçš„æ™ºèƒ½ä¸Šä¸‹æ–‡å¤„ç†"""
        # éªŒè¯é…ç½®
        if not self.valves.enable_context_processing:
            self.debug_log(1, "ä¸Šä¸‹æ–‡å¤„ç†å·²ç¦ç”¨", "âš ï¸")
            return messages
        
        # åªæœ‰å½“éœ€è¦å‘é‡æ£€ç´¢æ—¶æ‰éªŒè¯å‘é‡é…ç½®
        if not self.valves.enable_multimodal_vector and not self.valves.enable_text_vector:
            self.debug_log(1, "å‘é‡æ¨¡å‹å‡æœªå¯ç”¨ï¼Œä½¿ç”¨çº¯æ‘˜è¦æ¨¡å¼", "âš ï¸")
            token_limit = self.get_model_token_limit(model_name)
            return await self.recursive_summarize(messages, token_limit, __event_emitter__)
        
        token_limit = self.get_model_token_limit(model_name)
        current_tokens = self.count_messages_tokens(messages)
        
        self.debug_log(1, f"ä¸Šä¸‹æ–‡å¤„ç†: {len(messages)}æ¡æ¶ˆæ¯, {current_tokens}/{token_limit} tokens, æ¨¡å‹:{model_name}", "ğŸ¯")
        
        if current_tokens <= token_limit:
            self.debug_log(1, "å†…å®¹æœªè¶…é™ï¼Œæ— éœ€ä¸Šä¸‹æ–‡å¤„ç†", "âœ…")
            return messages
        
        await self.send_status(__event_emitter__, 
            f"å†…å®¹è¶…é™ ({current_tokens}/{token_limit})ï¼Œå¯åŠ¨ä¸Šä¸‹æ–‡å¤„ç†...", False, "ğŸš€")
        
        # æå–ç”¨æˆ·æŸ¥è¯¢
        user_query = None
        for msg in reversed(messages):
            if msg.get("role") == "user":
                user_query = msg.get("content", "")
                break
        
        if not user_query:
            self.debug_log(1, "æœªæ‰¾åˆ°ç”¨æˆ·æŸ¥è¯¢ï¼Œä½¿ç”¨é€’å½’æ‘˜è¦", "âš ï¸")
            return await self.recursive_summarize(messages, token_limit, __event_emitter__)
        
        # åˆ†ç‰‡å†å²æ¶ˆæ¯
        protected_count = self.valves.preserve_last_messages * 2
        protected_messages = messages[-protected_count:] if len(messages) > protected_count else messages
        history_messages = messages[:-protected_count] if len(messages) > protected_count else []
        
        if not history_messages:
            self.debug_log(1, "æ²¡æœ‰å†å²æ¶ˆæ¯å¯å¤„ç†ï¼Œä½¿ç”¨é€’å½’æ‘˜è¦", "âš ï¸")
            return await self.recursive_summarize(messages, token_limit, __event_emitter__)
        
        # æ™ºèƒ½åˆ†ç‰‡
        chunks = await self.chunk_messages_intelligently(history_messages)
        self.debug_log(2, f"åˆ›å»º {len(chunks)} ä¸ªæ™ºèƒ½åˆ†ç‰‡", "ğŸ“„")
        
        # è¯­ä¹‰æ£€ç´¢å’Œé‡æ’åº
        relevant_chunks = await self.semantic_search_and_rerank(user_query, chunks, __event_emitter__)
        
        # æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡
        system_messages = [msg for msg in messages if msg.get("role") == "system"]
        enhanced_context = []
        
        if relevant_chunks:
            references = []
            context_content = ""
            used_tokens = 0
            available_tokens = int(token_limit * self.valves.context_preserve_ratio)
            
            for i, chunk in enumerate(relevant_chunks):
                chunk_tokens = chunk["tokens"]
                if used_tokens + chunk_tokens <= available_tokens:
                    model_info = ""
                    if chunk.get("similarity_score"):
                        model_info = f"[ç›¸ä¼¼åº¦:{chunk['similarity_score']:.3f}] "
                    
                    context_content += f"\n### ğŸ“ ç›¸å…³ä¸Šä¸‹æ–‡ {i+1} {model_info}\n{chunk['content']}\n"
                    references.append(f"[REF-{i+1}]")
                    used_tokens += chunk_tokens
                    
                    chunk["reference_id"] = f"REF-{i+1}"
                else:
                    break
            
            if context_content:
                ref_list = ", ".join(references)
                strategy_info = f"ç­–ç•¥: {self.valves.vector_strategy.value}"
                enhanced_message = {
                    "role": "system",
                    "content": f"=== ğŸ” æ£€ç´¢å¢å¼ºä¸Šä¸‹æ–‡ ===\nåŸºäºæŸ¥è¯¢æ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹ ({ref_list}) | {strategy_info}:\n{context_content}\n\nğŸ’¡ è¯·åŸºäºä¸Šè¿°ä¸Šä¸‹æ–‡å’Œå¯¹è¯å†å²å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å¦‚æœå¼•ç”¨äº†ä¸Šä¸‹æ–‡å†…å®¹ï¼Œè¯·æ ‡æ³¨ç›¸åº”çš„å¼•ç”¨æ ‡è®°ã€‚"
                }
                enhanced_context.append(enhanced_message)
        
        # ç»„åˆæœ€ç»ˆæ¶ˆæ¯
        final_messages = system_messages + enhanced_context + protected_messages
        final_tokens = self.count_messages_tokens(final_messages)
        
        if final_tokens > token_limit:
            await self.send_status(__event_emitter__, "å¢å¼ºä¸Šä¸‹æ–‡ä»è¶…é™ï¼Œå¯åŠ¨é€’å½’æ‘˜è¦...", False, "ğŸ”„")
            return await self.recursive_summarize(final_messages, token_limit, __event_emitter__)
        else:
            await self.send_status(__event_emitter__, f"ä¸Šä¸‹æ–‡å¤„ç†å®Œæˆ ({current_tokens}â†’{final_tokens} tokens)", True, "ğŸ‰")
            self.debug_log(1, f"æœ€ç»ˆç»“æœ: {len(final_messages)} æ¡æ¶ˆæ¯, {final_tokens} tokens", "ğŸ‰")
            return final_messages

    # === ğŸš€ ä¸»è¦å…¥å£å‡½æ•° ===
    async def inlet(
        self,
        body: dict,
        user: Optional[dict] = None,
        __event_emitter__: Optional[Callable] = None,
    ) -> dict:
        """ä¸»å¤„ç†å…¥å£ - æ–°çš„å¤„ç†æµç¨‹"""
        # æ£€æŸ¥æ€»å¼€å…³
        if not self.toggle or not self.valves.enable_processing:
            return body

        messages = body.get("messages", [])
        if not messages:
            return body

        model_name = body.get("model", "")
        self.debug_log(1, f"ğŸš€ å¼€å§‹å¤„ç†: æ¨¡å‹={model_name}, æ¶ˆæ¯æ•°={len(messages)}", "ğŸš€")

        try:
            original_messages = messages.copy()
            processed_messages = messages
            
            # === ç¬¬ä¸€æ­¥ï¼šå¤šæ¨¡æ€å¤„ç†ï¼ˆæ— è®ºæ˜¯å¦è¶…é™éƒ½è¦æ£€æŸ¥ï¼‰ ===
            if self.should_process_multimodal(processed_messages, model_name):
                await self.send_status(__event_emitter__, "å¼€å§‹å¤šæ¨¡æ€å†…å®¹å¤„ç†...", False, "ğŸ–¼ï¸")
                processed_messages = await self.process_multimodal_content(processed_messages, __event_emitter__)
                self.debug_log(1, f"å¤šæ¨¡æ€å¤„ç†å®Œæˆ: {len(messages)}â†’{len(processed_messages)} æ¡æ¶ˆæ¯", "ğŸ–¼ï¸")
            
            # === ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥tokené™åˆ¶ï¼Œå†³å®šæ˜¯å¦éœ€è¦ä¸Šä¸‹æ–‡å¤„ç† ===
            token_limit = self.get_model_token_limit(model_name)
            current_tokens = self.count_messages_tokens(processed_messages)
            
            self.debug_log(1, f"Tokenæ£€æŸ¥: {current_tokens}/{token_limit} ({current_tokens/token_limit*100:.1f}%)", "ğŸ“Š")
            
            if current_tokens > token_limit and self.valves.enable_context_processing:
                await self.send_status(__event_emitter__, f"å†…å®¹è¶…é™ï¼Œå¯åŠ¨ä¸Šä¸‹æ–‡å¤„ç†...", False, "ğŸ“š")
                processed_messages = await self.process_context_with_retrieval(
                    processed_messages, model_name, __event_emitter__
                )
                self.debug_log(1, f"ä¸Šä¸‹æ–‡å¤„ç†å®Œæˆ: {current_tokens}â†’{self.count_messages_tokens(processed_messages)} tokens", "ğŸ“š")
            
            # === ç¬¬ä¸‰æ­¥ï¼šæ›´æ–°bodyå¹¶è¿”å›ç»“æœ ===
            final_tokens = self.count_messages_tokens(processed_messages)
            
            # ç»Ÿè®¡å¤„ç†æ•ˆæœ
            original_tokens = self.count_messages_tokens(original_messages)
            has_images = self.has_images_in_messages(original_messages)
            
            self.debug_log(1, f"âœ… å¤„ç†å®Œæˆ: {original_tokens}â†’{final_tokens} tokens, å›¾ç‰‡={has_images}, è¶…é™å¤„ç†={'æ˜¯' if current_tokens > token_limit else 'å¦'}", "ğŸ‰")
            
            # å‘å‰ç«¯å‘é€æœ€ç»ˆçŠ¶æ€
            if original_tokens != final_tokens or has_images:
                processing_info = []
                if has_images:
                    processing_info.append("å¤šæ¨¡æ€è½¬æ¢")
                if original_tokens != final_tokens:
                    processing_info.append(f"ä¸Šä¸‹æ–‡ä¼˜åŒ–({original_tokens}â†’{final_tokens})")
                
                await self.send_status(__event_emitter__, 
                    f"å¤„ç†å®Œæˆï¼š{', '.join(processing_info)}", True, "ğŸ‰")
            
            body["messages"] = processed_messages
            return body
            
        except Exception as e:
            await self.send_status(__event_emitter__, f"âŒ å¤„ç†å¤±è´¥: {str(e)}", True, "âŒ")
            self.debug_log(1, f"å¤„ç†å‡ºé”™: {e}", "âŒ")
            if self.valves.debug_level >= 2:
                import traceback
                traceback.print_exc()
            
            # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›åŸå§‹æ¶ˆæ¯
            return body

    async def outlet(
        self,
        body: dict,
        user: Optional[dict] = None,
        __event_emitter__: Optional[Callable] = None,
    ) -> dict:
        """è¾“å‡ºåå¤„ç†"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ è¾“å‡ºåå¤„ç†é€»è¾‘ï¼Œæ¯”å¦‚å¼•ç”¨æ ‡è®°çš„ç¾åŒ–ç­‰
        return body
